# Private RAG AI Agent

ì˜¨í”„ë ˆë¯¸ìŠ¤ ê¸°ë°˜ ê¸°ì—…ìš© RAG(Retrieval-Augmented Generation) ì‹œìŠ¤í…œ

## ë¹ ë¥¸ ì‹œì‘

```bash
# 1. Backend ì„¤ì •
cd backend
python -m venv venv311
venv311\Scripts\activate
pip install -r requirements.txt
python scripts/init_models.py

# 2. Ollama ëª¨ë¸ ë‹¤ìš´ë¡œë“œ
ollama pull llama3.1:8b-instruct-q4_K_M

# 3. ì‹¤í–‰
python app.py  # Backend
npm run dev    # Frontend (ë³„ë„ í„°ë¯¸ë„)
```

## ë¬¸ì„œ

- ğŸ“– [ì „ì²´ ë¬¸ì„œ](docs/README.md)
- ğŸš€ [ë¹ ë¥¸ ì‹œì‘ ê°€ì´ë“œ](docs/QUICKSTART.md)
- ğŸ“¦ [ì„¤ì¹˜ ê°€ì´ë“œ](docs/INSTALL.md)
- âš™ï¸ [Ollama ì„¤ì •](docs/OLLAMA_SETUP.md)
- ğŸ“ [í”„ë¡œì íŠ¸ êµ¬ì¡°](docs/PROJECT_STRUCTURE.md)

## ì£¼ìš” ê¸°ëŠ¥

- âœ… í•˜ì´ë¸Œë¦¬ë“œ ìì› ë¶„ë°° (ì„ë² ë”©: CPU, LLM: GPU)
- âœ… Layout-aware ë¬¸ì„œ ì²˜ë¦¬
- âœ… 100% ì˜¤í”„ë¼ì¸ ë™ì‘
- âœ… í• ë£¨ì‹œë„¤ì´ì…˜ ë°©ì§€

## ê¸°ìˆ  ìŠ¤íƒ

- Frontend: React + Vite
- Backend: Python Flask + LangChain
- LLM: Ollama (llama3.1:8b-instruct-q4_K_M)
- Vector DB: ChromaDB
- Embedding: bge-m3 (CPU)

---

ìì„¸í•œ ë‚´ìš©ì€ [docs/README.md](docs/README.md)ë¥¼ ì°¸ì¡°í•˜ì„¸ìš”.
