"""
=============================================================================
DocumentProcessor - ë¬¸ì„œ íŒŒì‹± ë° í‘œ ì¶”ì¶œ ëª¨ë“ˆ
=============================================================================

ì´ ëª¨ë“ˆì€ PDF, DOCX, Excel ë“± ë‹¤ì–‘í•œ ë¬¸ì„œì—ì„œ í…ìŠ¤íŠ¸ì™€ í‘œë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.
íŠ¹íˆ í‘œ(Table) ì²˜ë¦¬ë¥¼ ìœ„í•´ 5ê°€ì§€ ë°©ë²•ì„ ì§€ì›í•©ë‹ˆë‹¤:

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        ğŸ“Š í‘œ(Table) ì²˜ë¦¬ ë°©ë²• 5ê°€ì§€                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                             â”‚
â”‚  1ï¸âƒ£ pdfplumber í…ìŠ¤íŠ¸ í‘œ ì¶”ì¶œ                                               â”‚
â”‚     - ë°©ì‹: PDF ë‚´ë¶€ì˜ í…ìŠ¤íŠ¸ ê¸°ë°˜ í‘œ êµ¬ì¡°ë¥¼ ì§ì ‘ íŒŒì‹±                        â”‚
â”‚     - ì¥ì : ë¹ ë¥´ê³  ì •í™•í•¨, í…ìŠ¤íŠ¸ ê¸°ë°˜ PDFì— ìµœì                             â”‚
â”‚     - ë‹¨ì : ì´ë¯¸ì§€ë¡œ ëœ í‘œëŠ” ì¸ì‹ ë¶ˆê°€                                       â”‚
â”‚     - ë©”ì„œë“œ: _process_pdf_with_pdfplumber(), page.extract_tables()         â”‚
â”‚                                                                             â”‚
â”‚  2ï¸âƒ£ ì´ë¯¸ì§€ OCR (EasyOCR)                                                    â”‚
â”‚     - ë°©ì‹: í˜ì´ì§€ë¥¼ ì´ë¯¸ì§€ë¡œ ë³€í™˜ í›„ OCRë¡œ í…ìŠ¤íŠ¸ ì¶”ì¶œ                       â”‚
â”‚     - ì¥ì : ìŠ¤ìº” ë¬¸ì„œ, ì´ë¯¸ì§€ PDF ì²˜ë¦¬ ê°€ëŠ¥                                  â”‚
â”‚     - ë‹¨ì : í‘œ êµ¬ì¡° ì¸ì‹ ì–´ë ¤ì›€, ì†ë„ ëŠë¦¼                                   â”‚
â”‚     - ë©”ì„œë“œ: _extract_image_tables_with_ocr(), reader.readtext()           â”‚
â”‚                                                                             â”‚
â”‚  3ï¸âƒ£ OpenCV í‘œ ì„  ê°ì§€                                                       â”‚
â”‚     - ë°©ì‹: ì´ë¯¸ì§€ì—ì„œ ìˆ˜í‰/ìˆ˜ì§ ì„ ì„ ê°ì§€í•˜ì—¬ ì…€ ì˜ì—­ ë¶„ë¦¬                   â”‚
â”‚     - ì¥ì : ì„ ì´ ìˆëŠ” í‘œ ì •í™•í•˜ê²Œ ì¸ì‹, ì…€ ë‹¨ìœ„ OCR ê°€ëŠ¥                     â”‚
â”‚     - ë‹¨ì : ì„ ì´ ì—†ëŠ” í‘œëŠ” ì¸ì‹ ë¶ˆê°€                                        â”‚
â”‚     - ë©”ì„œë“œ: _detect_table_cells_opencv(), cv2.morphologyEx()              â”‚
â”‚                                                                             â”‚
â”‚  4ï¸âƒ£ EasyOCR ì¢Œí‘œ ê¸°ë°˜ ì¶”ë¡                                                   â”‚
â”‚     - ë°©ì‹: OCR ê²°ê³¼ì˜ ì¢Œí‘œ(bbox)ë¥¼ ë¶„ì„í•˜ì—¬ í–‰/ì—´ êµ¬ì¡° ì¶”ë¡                   â”‚
â”‚     - ì¥ì : ì„ ì´ ì—†ëŠ” í‘œë„ ì²˜ë¦¬ ê°€ëŠ¥                                        â”‚
â”‚     - ë‹¨ì : ë³µì¡í•œ í‘œ êµ¬ì¡°ì—ì„œ ì˜¤ë¥˜ ë°œìƒ ê°€ëŠ¥                                â”‚
â”‚     - ë©”ì„œë“œ: _extract_image_tables_with_ocr() ë‚´ ì¢Œí‘œ ê·¸ë£¹í™” ë¡œì§           â”‚
â”‚                                                                             â”‚
â”‚  5ï¸âƒ£ Column-first Contextual Table Parsing                                   â”‚
â”‚     - ë°©ì‹: ì—´ ë‹¨ìœ„ë¡œ ìˆœíšŒí•˜ë©° ë³‘í•© ì…€ ì±„ìš°ê¸° + ê³„ì¸µ êµ¬ì¡° í…ìŠ¤íŠ¸ ìƒì„±         â”‚
â”‚     - ì¥ì : ë³‘í•© ì…€ ì²˜ë¦¬, LLMì´ ì´í•´í•˜ê¸° ì‰¬ìš´ ê³„ì¸µí˜• ì¶œë ¥                     â”‚
â”‚     - ë‹¨ì : ë‹¨ìˆœí•œ í‘œì—ëŠ” ì˜¤ë²„í—¤ë“œ                                          â”‚
â”‚     - ë©”ì„œë“œ: _pdfplumber_table_to_markdown(), _excel_table_to_markdown()   â”‚
â”‚                                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                            ğŸ”„ ì²˜ë¦¬ ìš°ì„ ìˆœìœ„                                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                             â”‚
â”‚  PDF ì²˜ë¦¬ ì‹œ:                                                               â”‚
â”‚    1. OpenCV í‘œ ì„  ê°ì§€ (ìš°ì„ ) â†’ ì„±ê³µ ì‹œ ì…€ë³„ OCR                            â”‚
â”‚    2. pdfplumber í…ìŠ¤íŠ¸ í‘œ ì¶”ì¶œ (í´ë°±)                                       â”‚
â”‚    3. ì¼ë°˜ í…ìŠ¤íŠ¸ ì¶”ì¶œ                                                      â”‚
â”‚                                                                             â”‚
â”‚  Excel ì²˜ë¦¬ ì‹œ:                                                             â”‚
â”‚    1. openpyxl/xlrdë¡œ ì…€ ë°ì´í„° + ë³‘í•© ì…€ ì •ë³´ ì¶”ì¶œ                          â”‚
â”‚    2. Column-first Forward Fill ì ìš©                                        â”‚
â”‚    3. ê³„ì¸µí˜• í…ìŠ¤íŠ¸ + Markdown í…Œì´ë¸” ìƒì„±                                   â”‚
â”‚                                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ì‚¬ìš©ë²•:
    processor = DocumentProcessor()
    chunks = processor.extract_text_with_layout(file_path)
    
    # chunks êµ¬ì¡°:
    # [
    #     {"text": "...", "page": 1, "type": "text", "metadata": {...}},
    #     {"text": "[ê³„ì¸µí˜• í‘œ ë°ì´í„°]...", "page": 2, "type": "table", "metadata": {"has_table": True}},
    # ]
"""

import re
from pathlib import Path
from typing import List, Dict
import PyPDF2
from docx import Document

# pdfplumberë¥¼ ì‚¬ìš©í•œ í‘œ ì¶”ì¶œ (Python 3.14 í˜¸í™˜)
try:
    import pdfplumber
    HAS_PDFPLUMBER = True
    print("pdfplumber available: Table extraction enabled")
except ImportError:
    HAS_PDFPLUMBER = False
    print("Warning: pdfplumber not available, table extraction disabled")

# openpyxlì„ ì‚¬ìš©í•œ ì—‘ì…€ ì²˜ë¦¬
try:
    import openpyxl
    HAS_OPENPYXL = True
    print("openpyxl available: Excel file support enabled")
except ImportError:
    HAS_OPENPYXL = False
    print("Warning: openpyxl not available, Excel file support disabled")

# xlrdë¥¼ ì‚¬ìš©í•œ .xls íŒŒì¼ ì²˜ë¦¬
try:
    import xlrd
    HAS_XLRD = True
except ImportError:
    HAS_XLRD = False

# unstructuredëŠ” ì„ íƒì‚¬í•­ (Python 3.13 ë¯¸ë§Œì—ì„œë§Œ ì‘ë™)
try:
    from unstructured.partition.auto import partition
    from unstructured.chunking.title import chunk_by_title
    HAS_UNSTRUCTURED = True
except ImportError:
    HAS_UNSTRUCTURED = False
    print("Warning: unstructured not available, using pdfplumber or PyPDF2 fallback")

# EasyOCRì„ ì‚¬ìš©í•œ ì´ë¯¸ì§€ í…ìŠ¤íŠ¸ ì¶”ì¶œ
try:
    import easyocr
    HAS_EASYOCR = True
    print("EasyOCR available: Image text extraction enabled")
except ImportError:
    HAS_EASYOCR = False
    print("Warning: EasyOCR not available, image text extraction disabled")

# PILì„ ì‚¬ìš©í•œ ì´ë¯¸ì§€ ì²˜ë¦¬
try:
    from PIL import Image
    HAS_PIL = True
except ImportError:
    HAS_PIL = False
    print("Warning: Pillow not available, image processing disabled")

# OpenCVë¥¼ ì‚¬ìš©í•œ í‘œ ì„  ê°ì§€
try:
    import cv2
    HAS_CV2 = True
    print("OpenCV available: Advanced table detection enabled")
except ImportError:
    HAS_CV2 = False
    print("Warning: OpenCV not available, advanced table detection disabled")

# pdf2imageë¥¼ ì‚¬ìš©í•œ PDF ì´ë¯¸ì§€ ë³€í™˜
try:
    from pdf2image import convert_from_path
    HAS_PDF2IMAGE = True
except ImportError:
    HAS_PDF2IMAGE = False
    print("Warning: pdf2image not available, PDF OCR disabled")

class DocumentProcessor:
    """Layout-aware ë¬¸ì„œ ì²˜ë¦¬ í´ë˜ìŠ¤"""
    
    def __init__(self):
        self.chunk_size = 1000
        self.chunk_overlap = 200
        self.ocr_reader = None  # Lazy loading for EasyOCR
    
    def _get_ocr_reader(self):
        """OCR ë¦¬ë” ì´ˆê¸°í™” (ì§€ì—° ë¡œë”©)"""
        if self.ocr_reader is None and HAS_EASYOCR:
            print("[DocumentProcessor] EasyOCR ëª¨ë¸ ë¡œë”© ì¤‘... (ì²˜ìŒ ì‹¤í–‰ ì‹œ ì‹œê°„ì´ ì†Œìš”ë©ë‹ˆë‹¤)")
            self.ocr_reader = easyocr.Reader(['ko', 'en'], gpu=False)  # í•œêµ­ì–´ + ì˜ì–´ ì§€ì›
            print("[DocumentProcessor] EasyOCR ëª¨ë¸ ë¡œë”© ì™„ë£Œ")
        return self.ocr_reader
    
    def extract_text_with_layout(self, file_path: Path) -> List[Dict]:
        """
        ë¬¸ì„œì—ì„œ í…ìŠ¤íŠ¸, í‘œ, ì´ë¯¸ì§€ë¥¼ ì¶”ì¶œí•˜ì—¬ êµ¬ì¡°í™”ëœ ì²­í¬ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜
        ê° ì²­í¬ëŠ” í˜ì´ì§€ ë²ˆí˜¸ì™€ ë©”íƒ€ë°ì´í„°ë¥¼ í¬í•¨
        """
        file_ext = file_path.suffix.lower()
        
        if file_ext == ".pdf":
            return self._process_pdf(file_path)
        elif file_ext == ".docx":
            return self._process_docx(file_path)
        elif file_ext in [".txt", ".md"]:
            return self._process_text(file_path)
        elif file_ext in [".xlsx", ".xls"]:
            return self._process_excel(file_path)
        elif file_ext in [".png", ".jpg", ".jpeg", ".gif", ".bmp", ".tiff", ".tif", ".webp"]:
            return self._process_image(file_path)
        else:
            raise ValueError(f"Unsupported file type: {file_ext}")
    
    def _process_pdf(self, file_path: Path) -> List[Dict]:
        """PDF ì²˜ë¦¬ (ìŠ¤ë§ˆíŠ¸ í‘œ ê°ì§€ + ìë™ ì¶”ì¶œ)"""
        chunks = []
        
        # ====== ìŠ¤ë§ˆíŠ¸ í‘œ ê°ì§€ ëª¨ë“œ ======
        # pdfplumberê°€ ìˆìœ¼ë©´ ë¨¼ì € í‘œê°€ ìˆëŠ”ì§€ í™•ì¸í•˜ê³ ,
        # í‘œê°€ ìˆìœ¼ë©´ pdfplumberë¡œ, ì—†ìœ¼ë©´ PyPDF2ë¡œ ì²˜ë¦¬
        
        if HAS_PDFPLUMBER:
            try:
                # 1ë‹¨ê³„: í‘œ ì¡´ì¬ ì—¬ë¶€ ë¹ ë¥´ê²Œ í™•ì¸
                has_tables = False
                with pdfplumber.open(file_path) as pdf:
                    for page in pdf.pages[:5]:  # ì²˜ìŒ 5í˜ì´ì§€ë§Œ ê²€ì‚¬ (ì†ë„ ìµœì í™”)
                        tables = page.extract_tables()
                        if tables and any(t for t in tables if t and len(t) > 1):
                            has_tables = True
                            break
                
                if has_tables:
                    # í‘œê°€ ê°ì§€ë¨ â†’ pdfplumberë¡œ í‘œ+í…ìŠ¤íŠ¸ ëª¨ë‘ ì¶”ì¶œ
                    print(f"[DocumentProcessor] í‘œ ê°ì§€ë¨! pdfplumberë¡œ í‘œ ì¶”ì¶œ ëª¨ë“œ í™œì„±í™”")
                    self._process_pdf_with_pdfplumber(file_path, chunks)
                    
                    # í‘œ ì²­í¬ ìˆ˜ ì¹´ìš´íŠ¸
                    table_count = sum(1 for c in chunks if c.get("type") == "table")
                    text_count = sum(1 for c in chunks if c.get("type") == "text")
                    print(f"[DocumentProcessor] pdfplumber ì²˜ë¦¬ ì™„ë£Œ: í…ìŠ¤íŠ¸ {text_count}ê°œ, í‘œ {table_count}ê°œ")
                else:
                    # í‘œ ì—†ìŒ â†’ PyPDF2ë¡œ ë¹ ë¥´ê²Œ í…ìŠ¤íŠ¸ë§Œ ì¶”ì¶œ
                    print(f"[DocumentProcessor] í‘œ ì—†ìŒ, PyPDF2ë¡œ í…ìŠ¤íŠ¸ ì¶”ì¶œ")
                    self._process_pdf_with_pypdf2(file_path, chunks)
                    print(f"[DocumentProcessor] PyPDF2 ì²˜ë¦¬ ì™„ë£Œ: {len(chunks)} ì²­í¬")
                    
            except Exception as e:
                print(f"[DocumentProcessor] pdfplumber ì˜¤ë¥˜: {e}, PyPDF2ë¡œ í´ë°±")
                chunks = []
                self._process_pdf_with_pypdf2(file_path, chunks)
        
        # pdfplumberê°€ ì—†ìœ¼ë©´ unstructured ì‹œë„
        elif HAS_UNSTRUCTURED:
            try:
                # Unstructuredë¥¼ ì‚¬ìš©í•œ êµ¬ì¡°í™”ëœ ì¶”ì¶œ
                elements = partition(filename=str(file_path), strategy="hi_res")
                
                page_num = 1
                current_text = ""
                
                for element in elements:
                    element_text = str(element)
                    
                    # í˜ì´ì§€ ë²ˆí˜¸ ê°ì§€
                    if hasattr(element, 'metadata') and hasattr(element.metadata, 'page_number'):
                        new_page = element.metadata.page_number
                        if new_page != page_num:
                            # í˜ì´ì§€ ë³€ê²½ ì‹œ í˜„ì¬ ì²­í¬ ì €ì¥
                            if current_text.strip():
                                chunks.append({
                                    "text": current_text.strip(),
                                    "page": page_num,
                                    "type": "text"
                                })
                            current_text = ""
                            page_num = new_page
                    
                    # í‘œ(table) ì²˜ë¦¬
                    if element.category == "Table":
                        # í‘œë¥¼ êµ¬ì¡°í™”ëœ í…ìŠ¤íŠ¸ í˜•ì‹ìœ¼ë¡œ ë³€í™˜
                        table_text = self._table_to_markdown(element_text)
                        chunks.append({
                            "text": f"\n\n[í‘œ ì‹œì‘]\n{table_text}\n[í‘œ ë]\n\n",
                            "page": page_num,
                            "type": "table"
                        })
                    else:
                        current_text += element_text + "\n\n"
                
                # ë§ˆì§€ë§‰ ì²­í¬ ì €ì¥
                if current_text.strip():
                    chunks.append({
                        "text": current_text.strip(),
                        "page": page_num,
                        "type": "text"
                    })
            
                print(f"[DocumentProcessor] unstructuredë¡œ PDF ì²˜ë¦¬ ì™„ë£Œ: {len(chunks)} ì²­í¬")
            
            except Exception as e:
                # Fallback: pdfplumber ì‚¬ìš©
                print(f"[DocumentProcessor] Unstructured ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
                chunks = []
                if HAS_PDFPLUMBER:
                    try:
                        self._process_pdf_with_pdfplumber(file_path, chunks)
                        print(f"[DocumentProcessor] pdfplumberë¡œ PDF ì²˜ë¦¬ ì™„ë£Œ: {len(chunks)} ì²­í¬")
                    except Exception as e2:
                        print(f"[DocumentProcessor] pdfplumber ì²˜ë¦¬ ì‹¤íŒ¨: {e2}")
                        chunks = []
                        self._process_pdf_with_pypdf2(file_path, chunks)
                else:
                    self._process_pdf_with_pypdf2(file_path, chunks)
        
        # 2ìˆœìœ„: pdfplumber ì‚¬ìš©
        elif HAS_PDFPLUMBER:
            try:
                self._process_pdf_with_pdfplumber(file_path, chunks)
                print(f"[DocumentProcessor] pdfplumberë¡œ PDF ì²˜ë¦¬ ì™„ë£Œ: {len(chunks)} ì²­í¬")
            except Exception as e:
                print(f"[DocumentProcessor] pdfplumber ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
                chunks = []
                self._process_pdf_with_pypdf2(file_path, chunks)
        
        else:
            # ë‘˜ ë‹¤ ì—†ìœ¼ë©´ PyPDF2 ì‚¬ìš©
            self._process_pdf_with_pypdf2(file_path, chunks)
        
        # ì²­í¬ ë¶„í• 
        return self._chunk_documents(chunks)
    
    def _process_pdf_with_pdfplumber(self, file_path: Path, chunks: List[Dict]):
        """
        ========================================================================
        [ë°©ë²• 1] pdfplumberë¥¼ ì‚¬ìš©í•œ PDF ì²˜ë¦¬
        ========================================================================
        
        ì²˜ë¦¬ ìˆœì„œ:
        1. OpenCV í‘œ ì„  ê°ì§€ (ìš°ì„ ) - _detect_table_cells_opencv()
        2. pdfplumber í…ìŠ¤íŠ¸ í‘œ ì¶”ì¶œ (í´ë°±) - page.extract_tables()
        3. ì¼ë°˜ í…ìŠ¤íŠ¸ ì¶”ì¶œ - page.extract_text()
        
        ì¥ì : í…ìŠ¤íŠ¸ ê¸°ë°˜ PDFì—ì„œ ë¹ ë¥´ê³  ì •í™•í•œ í‘œ ì¶”ì¶œ
        ë‹¨ì : ì´ë¯¸ì§€ë¡œ ëœ í‘œëŠ” ì¸ì‹ ë¶ˆê°€ (OpenCV/OCRë¡œ ëŒ€ì²´)
        """
        with pdfplumber.open(file_path) as pdf:
            for page_num, page in enumerate(pdf.pages, 1):
                table_bboxes = []  # í‘œ ì˜ì—­ ì¢Œí‘œ ì €ì¥ (í…ìŠ¤íŠ¸ ì¤‘ë³µ ë°©ì§€ìš©)
                tables_found = 0
                
                # ====== 1ë‹¨ê³„: OpenCV ê¸°ë°˜ í‘œ ê°ì§€ (ìš°ì„ ) ======
                if HAS_CV2 and HAS_EASYOCR and HAS_PIL:
                    print(f"[OpenCV] í˜ì´ì§€ {page_num}: OpenCV í‘œ ê°ì§€ ì‹œë„ (ìš°ì„ )")
                    image_tables = self._extract_image_tables_with_ocr(page, page_num)
                    if image_tables:
                        chunks.extend(image_tables)
                        tables_found += len(image_tables)
                        print(f"[OpenCV] í˜ì´ì§€ {page_num}: OpenCVë¡œ í‘œ {len(image_tables)}ê°œ ì¶”ì¶œ ì„±ê³µ!")
                    else:
                        print(f"[OpenCV] í˜ì´ì§€ {page_num}: OpenCV í‘œ ê°ì§€ ì‹¤íŒ¨ -> pdfplumberë¡œ ì „í™˜")
                
                # ====== 2ë‹¨ê³„: pdfplumber í…ìŠ¤íŠ¸ ê¸°ë°˜ í‘œ ì¶”ì¶œ (OpenCV ì‹¤íŒ¨ ì‹œ) ======
                if tables_found == 0:
                    tables = page.extract_tables()
                    
                    if tables:
                        for table_idx, table in enumerate(tables):
                            if table and len(table) > 1:  # ìµœì†Œ 2í–‰ ì´ìƒ
                                # í‘œë¥¼ Markdownìœ¼ë¡œ ë³€í™˜ (Cell Merging + Fill-down ì ìš©)
                                table_text = self._pdfplumber_table_to_markdown(table)
                                if table_text.strip():
                                    chunks.append({
                                        "text": f"\n\n[í‘œ {table_idx + 1} ì‹œì‘]\n{table_text}\n[í‘œ {table_idx + 1} ë]\n\n",
                                        "page": page_num,
                                        "type": "table"
                                    })
                                    tables_found += 1
                                    
                                    # í‘œ ë¯¸ë¦¬ë³´ê¸° ë¡œê·¸ (ì²˜ìŒ 3í–‰ë§Œ)
                                    preview_lines = table_text.split('\n')[:5]
                                    preview = '\n    '.join(preview_lines)
                                    print(f"[pdfplumber TABLE] í˜ì´ì§€ {page_num}, í‘œ {table_idx + 1} ({len(table)}í–‰ x {len(table[0]) if table[0] else 0}ì—´)")
                                    print(f"    {preview}")
                                    if len(table_text.split('\n')) > 5:
                                        print(f"    ... (ì´ {len(table)}í–‰)")
                
                # ====== 3ë‹¨ê³„: ì¼ë°˜ í…ìŠ¤íŠ¸ ì¶”ì¶œ ======
                text = page.extract_text()
                if text and text.strip():
                    chunks.append({
                        "text": text.strip(),
                        "page": page_num,
                        "type": "text"
                    })
    
    def _pdfplumber_table_to_markdown(self, table: List[List]) -> str:
        """
        ========================================================================
        [ë°©ë²• 5] Column-first Contextual Table Parsing
        ========================================================================
        
        pdfplumberë¡œ ì¶”ì¶œí•œ í‘œë¥¼ ê³„ì¸µí˜• í…ìŠ¤íŠ¸ + Markdownìœ¼ë¡œ ë³€í™˜
        
        í•µì‹¬ ë¡œì§:
        1. Column-wise Forward Fill: ì—´ ë‹¨ìœ„ë¡œ ìˆœíšŒí•˜ë©° ë¹ˆ ì…€ì„ ìœ„ìª½ ê°’ìœ¼ë¡œ ì±„ì›€
        2. Hierarchical Text Construction: "ì—´1 > ì—´2 > ì—´3: ê°’" í˜•íƒœë¡œ ê³„ì¸µ êµ¬ì¡° í‘œí˜„
        3. Empty Cell Intelligence: ë³‘í•©ëœ ì…€ ì •ë³´ë¥¼ ì°¸ì¡°í•˜ì—¬ ë°ì´í„° ì±„ìš°ê¸°
        
        ì¶œë ¥ í˜•ì‹:
            [ê³„ì¸µí˜• í‘œ ë°ì´í„°]
              - ëŒ€ë¶„ë¥˜ > ì¤‘ë¶„ë¥˜ > í•­ëª© >> ê¸ˆì•¡: 1000ì›
            
            [í‘œ ì›ë³¸ (Markdown)]
            | ì—´1 | ì—´2 | ì—´3 |
            | --- | --- | --- |
            | ... | ... | ... |
        
        ì¥ì : LLMì´ í‘œ ì¡°ê°ì„ ë°›ì•„ë„ ìƒìœ„ ê³„ì¸µ êµ¬ì¡°ë¥¼ ìƒì§€ ì•ŠìŒ
        """
        if not table or len(table) < 1:
            return ""
        
        # ====== 1ë‹¨ê³„: ì…€ ì •ë¦¬ ë° ë¹ˆ í–‰ ì œê±° ======
        cleaned_table = []
        for row in table:
            if row and any(cell for cell in row):
                # None, ì¤„ë°”ê¿ˆ, ê³µë°± ì •ë¦¬
                cleaned_row = []
                for cell in row:
                    if cell is None:
                        cleaned_row.append("")
                    else:
                        # ì¤„ë°”ê¿ˆì„ ê³µë°±ìœ¼ë¡œ ë³€í™˜, ì—°ì† ê³µë°± ì œê±°
                        cell_text = str(cell).replace("\n", " ").strip()
                        cell_text = " ".join(cell_text.split())
                        cleaned_row.append(cell_text)
                cleaned_table.append(cleaned_row)
        
        if not cleaned_table:
            return ""
        
        # ====== 2ë‹¨ê³„: ì—´ ìˆ˜ ë§ì¶”ê¸° ======
        max_cols = max(len(row) for row in cleaned_table)
        for row in cleaned_table:
            while len(row) < max_cols:
                row.append("")
        
        # ====== 3ë‹¨ê³„: Cell Merging (Fill-down) ì²˜ë¦¬ ======
        # ëª¨ë“  ì—´ì— ëŒ€í•´ ë¹ˆ ì…€ì€ ìœ„ìª½ ê°’ìœ¼ë¡œ ì±„ì›€
        for col_idx in range(max_cols):
            last_value = ""
            for row_idx in range(len(cleaned_table)):
                cell_value = cleaned_table[row_idx][col_idx]
                if cell_value:
                    last_value = cell_value
                elif last_value and row_idx > 0:
                    # ë¹ˆ ì…€: ìœ„ìª½ ê°’ìœ¼ë¡œ ì±„ì›€ (Fill-down)
                    cleaned_table[row_idx][col_idx] = last_value
        
        # ====== 4ë‹¨ê³„: ë¹ˆ ì—´ ì œê±° ======
        cols_to_keep = []
        for col_idx in range(max_cols):
            if any(row[col_idx].strip() for row in cleaned_table):
                cols_to_keep.append(col_idx)
        
        if cols_to_keep:
            cleaned_table = [[row[col_idx] for col_idx in cols_to_keep] for row in cleaned_table]
            max_cols = len(cols_to_keep)
        
        if max_cols == 0:
            return ""
        
        # ====== 5ë‹¨ê³„: ê³„ì¸µí˜• í…ìŠ¤íŠ¸ + Markdown Table ìƒì„± ======
        
        # í—¤ë” í–‰ (ì²« ë²ˆì§¸ í–‰)
        headers = cleaned_table[0]
        # ë¹ˆ í—¤ë”ëŠ” "ì—´1", "ì—´2"... ë¡œ ì±„ì›€
        for i, h in enumerate(headers):
            if not h.strip():
                headers[i] = f"ì—´{i+1}"
        
        output_lines = []
        
        # ====== ê³„ì¸µí˜• í…ìŠ¤íŠ¸ ìƒì„± (Hierarchical Text Construction) ======
        # ê° í–‰ì„ "ì—´1 > ì—´2 > ì—´3: ê°’" í˜•íƒœë¡œ ë³€í™˜
        output_lines.append("[ê³„ì¸µí˜• í‘œ ë°ì´í„°]")
        
        for row_idx, row in enumerate(cleaned_table[1:], 1):
            # ê³„ì¸µ êµ¬ì¡° íŒŒì•…: ì™¼ìª½ë¶€í„° ì¹´í…Œê³ ë¦¬, ì˜¤ë¥¸ìª½ì´ ê°’
            hierarchy_parts = []
            value_parts = []
            
            for col_idx, cell in enumerate(row):
                if not cell.strip():
                    continue
                    
                header = headers[col_idx] if col_idx < len(headers) else f"ì—´{col_idx+1}"
                
                # ë§ˆì§€ë§‰ ì—´ ë˜ëŠ” ìˆ«ì/ê¸ˆì•¡ì´ í¬í•¨ëœ ì—´ì€ ê°’ìœ¼ë¡œ ì²˜ë¦¬
                is_value = (col_idx >= len(row) - 2) or \
                           any(c.isdigit() for c in cell) or \
                           any(unit in cell for unit in ['ì›', '%', 'ê°œ', 'ê±´', 'ëª…', 'ì¼'])
                
                if is_value and hierarchy_parts:
                    value_parts.append(f"{header}: {cell}")
                else:
                    hierarchy_parts.append(cell)
            
            # ê³„ì¸µ êµ¬ì¡° ë¬¸ì¥ ìƒì„±
            if hierarchy_parts or value_parts:
                if hierarchy_parts and value_parts:
                    hierarchy_str = " > ".join(hierarchy_parts)
                    value_str = ", ".join(value_parts)
                    output_lines.append(f"  - {hierarchy_str} >> {value_str}")
                elif hierarchy_parts:
                    output_lines.append(f"  - " + " > ".join(hierarchy_parts))
                elif value_parts:
                    output_lines.append(f"  - " + ", ".join(value_parts))
        
        output_lines.append("")
        
        # ====== Markdown Tableë„ í•¨ê»˜ ìƒì„± (ì°¸ì¡°ìš©) ======
        output_lines.append("[í‘œ ì›ë³¸ (Markdown)]")
        output_lines.append("| " + " | ".join(headers) + " |")
        output_lines.append("| " + " | ".join(["---"] * max_cols) + " |")
        
        for row in cleaned_table[1:]:
            escaped_row = [cell.replace("|", "\\|") for cell in row]
            output_lines.append("| " + " | ".join(escaped_row) + " |")
        
        return "\n".join(output_lines)
    
    def _detect_table_cells_opencv(self, image_np, line_min_width=15):
        """
        ========================================================================
        [ë°©ë²• 3] OpenCV í‘œ ì„  ê°ì§€
        ========================================================================
        
        ì´ë¯¸ì§€ì—ì„œ ìˆ˜í‰/ìˆ˜ì§ ì„ ì„ ê°ì§€í•˜ì—¬ í‘œì˜ ì…€ ì˜ì—­ì„ ë¶„ë¦¬í•©ë‹ˆë‹¤.
        
        ì²˜ë¦¬ ë‹¨ê³„:
        1. ê·¸ë ˆì´ìŠ¤ì¼€ì¼ ë³€í™˜: cv2.cvtColor(BGR2GRAY)
        2. ì´ì§„í™”: cv2.threshold() - ì„ ì„ í‘/ë°±ìœ¼ë¡œ êµ¬ë¶„
        3. ìˆ˜í‰ì„  ê°ì§€: morphologyEx(MORPH_OPEN, kernal_h)
        4. ìˆ˜ì§ì„  ê°ì§€: morphologyEx(MORPH_OPEN, kernal_v)
        5. ì„  ê²°í•©: img_bin_h | img_bin_v
        6. íŒ½ì°½: cv2.dilate() - ëŠì–´ì§„ ì„  ì—°ê²°
        7. ì…€ ì˜ì—­ ì¶”ì¶œ: cv2.connectedComponentsWithStats()
        
        Args:
            image_np: numpy array í˜•íƒœì˜ ì´ë¯¸ì§€
            line_min_width: ì„ ìœ¼ë¡œ ì¸ì‹í•  ìµœì†Œ í”½ì…€ í¬ê¸° (ê¸°ë³¸ 15px)
            
        Returns:
            list of (x, y, w, h) íŠœí”Œ - ê° ì…€ì˜ ìœ„ì¹˜ì™€ í¬ê¸°
        
        ì¥ì : ì„ ì´ ìˆëŠ” í‘œë¥¼ ì •í™•í•˜ê²Œ ì…€ ë‹¨ìœ„ë¡œ ë¶„ë¦¬
        ë‹¨ì : ì„ ì´ ì—†ëŠ” í‘œëŠ” ì¸ì‹ ë¶ˆê°€
        """
        import numpy as np
        
        if not HAS_CV2:
            return []
        
        try:
            # 1. ê·¸ë ˆì´ìŠ¤ì¼€ì¼ ë³€í™˜
            if len(image_np.shape) == 3:
                gray_scale = cv2.cvtColor(image_np, cv2.COLOR_BGR2GRAY)
            else:
                gray_scale = image_np
            
            # 2. ì´ì§„í™” (Threshold)
            _, img_bin = cv2.threshold(gray_scale, 150, 255, cv2.THRESH_BINARY)
            img_bin = ~img_bin  # ë°˜ì „ (ì„ ì´ í°ìƒ‰ì´ ë˜ë„ë¡)
            
            # 3. ìˆ˜í‰/ìˆ˜ì§ ì»¤ë„ ìƒì„±
            kernal_h = np.ones((1, line_min_width), np.uint8)  # ìˆ˜í‰ì„  ê°ì§€
            kernal_v = np.ones((line_min_width, 1), np.uint8)  # ìˆ˜ì§ì„  ê°ì§€
            
            # 4. ëª¨í´ë¡œì§€ ì—°ì‚°ìœ¼ë¡œ ì„  ê°ì§€
            img_bin_h = cv2.morphologyEx(img_bin, cv2.MORPH_OPEN, kernal_h)
            img_bin_v = cv2.morphologyEx(img_bin, cv2.MORPH_OPEN, kernal_v)
            
            # 5. ìˆ˜í‰ì„  + ìˆ˜ì§ì„  ê²°í•©
            img_bin_final = img_bin_h | img_bin_v
            
            # 6. íŒ½ì°½ìœ¼ë¡œ ì„  ì—°ê²°
            final_kernel = np.ones((3, 3), np.uint8)
            img_bin_final = cv2.dilate(img_bin_final, final_kernel, iterations=1)
            
            # 7. ì—°ê²°ëœ ì»´í¬ë„ŒíŠ¸ ë¶„ì„ (ì…€ ì˜ì—­ ê°ì§€)
            _, labels, stats, _ = cv2.connectedComponentsWithStats(
                img_bin_final, connectivity=8, ltype=cv2.CV_32S
            )
            
            # 8. ì…€ ì˜ì—­ ì¶”ì¶œ (ë°°ê²½ ì œì™¸, stats[0]ì€ ë°°ê²½)
            cells = []
            for i in range(2, len(stats)):  # 0: ë°°ê²½, 1: ì „ì²´ í‘œ í…Œë‘ë¦¬, 2+: ì…€ë“¤
                x, y, w, h, area = stats[i]
                
                # ë„ˆë¬´ ì‘ê±°ë‚˜ ë„ˆë¬´ í° ì˜ì—­ ì œì™¸
                if w > 20 and h > 10 and area > 200 and area < (image_np.shape[0] * image_np.shape[1] * 0.5):
                    cells.append((x, y, w, h))
            
            print(f"[OpenCV] í‘œ ì…€ {len(cells)}ê°œ ê°ì§€ë¨")
            return cells
            
        except Exception as e:
            print(f"[OpenCV] í‘œ ì…€ ê°ì§€ ì˜¤ë¥˜: {e}")
            return []
    
    def _ocr_table_cells(self, image_np, cells, page_num: int) -> List[Dict]:
        """
        ========================================================================
        [ë°©ë²• 3 ë³´ì¡°] OpenCVë¡œ ê°ì§€ëœ ì…€ì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ
        ========================================================================
        
        _detect_table_cells_opencv()ì—ì„œ ê°ì§€ëœ ì…€ ì˜ì—­ì„ í¬ë¡­í•˜ì—¬
        ê° ì…€ë³„ë¡œ EasyOCRì„ ìˆ˜í–‰í•˜ê³ , ì¢Œí‘œ ê¸°ë°˜ìœ¼ë¡œ í–‰/ì—´ì„ ì¬êµ¬ì„±í•©ë‹ˆë‹¤.
        
        ì²˜ë¦¬ ë‹¨ê³„:
        1. ê° ì…€ ì˜ì—­ ì´ë¯¸ì§€ í¬ë¡­
        2. EasyOCRë¡œ í…ìŠ¤íŠ¸ ì¶”ì¶œ
        3. Yì¢Œí‘œë¡œ í–‰ ê·¸ë£¹í™” (í—ˆìš© ì˜¤ì°¨ 20px)
        4. Xì¢Œí‘œë¡œ ì—´ ì •ë ¬
        5. Markdown í…Œì´ë¸”ë¡œ ë³€í™˜
        
        Args:
            image_np: ì›ë³¸ ì´ë¯¸ì§€ (numpy array)
            cells: (x, y, w, h) íŠœí”Œ ë¦¬ìŠ¤íŠ¸ - OpenCVì—ì„œ ê°ì§€ëœ ì…€ ì¢Œí‘œ
            page_num: í˜ì´ì§€ ë²ˆí˜¸
            
        Returns:
            ì²­í¬ ë¦¬ìŠ¤íŠ¸ [{"text": "...", "page": N, "type": "table"}]
        """
        chunks = []
        
        if not cells or not HAS_EASYOCR:
            return chunks
        
        try:
            reader = self._get_ocr_reader()
            if not reader:
                return chunks
            
            import numpy as np
            
            # ê° ì…€ì—ì„œ OCR ìˆ˜í–‰
            cell_data = []
            for (x, y, w, h) in cells:
                # ì…€ ì˜ì—­ í¬ë¡­ (ì•½ê°„ì˜ íŒ¨ë”© ì¶”ê°€)
                pad = 2
                y1, y2 = max(0, y + pad), min(image_np.shape[0], y + h - pad)
                x1, x2 = max(0, x + pad), min(image_np.shape[1], x + w - pad)
                
                cell_img = image_np[y1:y2, x1:x2]
                
                if cell_img.size == 0:
                    continue
                
                # OCR
                results = reader.readtext(cell_img, detail=0, paragraph=True)
                text = " ".join(results).strip() if results else ""
                
                # ì…€ ì¤‘ì‹¬ ì¢Œí‘œ
                center_x = x + w // 2
                center_y = y + h // 2
                
                cell_data.append({
                    "text": text,
                    "x": center_x,
                    "y": center_y,
                    "w": w,
                    "h": h
                })
            
            if not cell_data:
                return chunks
            
            # Yì¢Œí‘œë¡œ í–‰ ê·¸ë£¹í™” (í—ˆìš© ì˜¤ì°¨ 20í”½ì…€)
            cell_data.sort(key=lambda c: c["y"])
            rows = []
            current_row = [cell_data[0]]
            current_y = cell_data[0]["y"]
            
            for cell in cell_data[1:]:
                if abs(cell["y"] - current_y) <= 20:
                    current_row.append(cell)
                else:
                    rows.append(sorted(current_row, key=lambda c: c["x"]))
                    current_row = [cell]
                    current_y = cell["y"]
            rows.append(sorted(current_row, key=lambda c: c["x"]))
            
            # Markdown í…Œì´ë¸”ë¡œ ë³€í™˜
            table_rows = [[cell["text"] for cell in row] for row in rows]
            
            if len(table_rows) >= 2:
                table_text = self._pdfplumber_table_to_markdown(table_rows)
                
                if table_text.strip():
                    chunks.append({
                        "text": f"\n\n[OpenCV í‘œ ê°ì§€ - {len(rows)}í–‰ x {len(rows[0]) if rows else 0}ì—´]\n{table_text}\n[í‘œ ë]\n\n",
                        "page": page_num,
                        "type": "table"
                    })
                    
                    # ë¡œê·¸ ì¶œë ¥
                    preview_lines = table_text.split('\n')[:5]
                    preview = '\n    '.join(preview_lines)
                    print(f"[OpenCV TABLE] í˜ì´ì§€ {page_num}: {len(rows)}í–‰ x {len(rows[0]) if rows else 0}ì—´")
                    print(f"    {preview}")
            
            return chunks
            
        except Exception as e:
            print(f"[OpenCV] OCR í‘œ ì¶”ì¶œ ì˜¤ë¥˜: {e}")
            return chunks
    
    def _extract_image_tables_with_ocr(self, page, page_num: int) -> List[Dict]:
        """
        ========================================================================
        [ë°©ë²• 2, 3, 4 í†µí•©] ì´ë¯¸ì§€ ê¸°ë°˜ í‘œ ì¶”ì¶œ (OCR)
        ========================================================================
        
        pdfplumber í˜ì´ì§€ë¥¼ ì´ë¯¸ì§€ë¡œ ë³€í™˜í•œ í›„ í‘œë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.
        
        ì²˜ë¦¬ ìˆœì„œ (ìš°ì„ ìˆœìœ„ëŒ€ë¡œ):
        1. [ë°©ë²• 3] OpenCV í‘œ ì„  ê°ì§€ â†’ ì…€ë³„ OCR
           - _detect_table_cells_opencv()ë¡œ ì…€ ì˜ì—­ ê°ì§€
           - _ocr_table_cells()ë¡œ ê° ì…€ OCR
           
        2. [ë°©ë²• 4] EasyOCR ì¢Œí‘œ ê¸°ë°˜ ì¶”ë¡  (OpenCV ì‹¤íŒ¨ ì‹œ)
           - reader.readtext()ë¡œ ì „ì²´ OCR
           - bbox ì¢Œí‘œë¥¼ ë¶„ì„í•˜ì—¬ í–‰/ì—´ êµ¬ì¡° ì¶”ë¡ 
           - Yì¢Œí‘œë¡œ í–‰ ê·¸ë£¹í™”, Xì¢Œí‘œë¡œ ì—´ ì •ë ¬
           
        3. [ë°©ë²• 2] ë‹¨ìˆœ EasyOCR (êµ¬ì¡°í™” ì‹¤íŒ¨ ì‹œ)
           - í…ìŠ¤íŠ¸ë§Œ ì¶”ì¶œí•˜ì—¬ ë°˜í™˜
        
        ì¥ì : ìŠ¤ìº” ë¬¸ì„œ, ì´ë¯¸ì§€ PDF ì²˜ë¦¬ ê°€ëŠ¥
        ë‹¨ì : ì†ë„ ëŠë¦¼, ë³µì¡í•œ í‘œì—ì„œ ì˜¤ë¥˜ ê°€ëŠ¥
        """
        chunks = []
        
        if not HAS_EASYOCR or not HAS_PIL:
            return chunks
        
        try:
            # í˜ì´ì§€ë¥¼ ì´ë¯¸ì§€ë¡œ ë³€í™˜
            page_image = page.to_image(resolution=150)
            pil_image = page_image.original
            
            # RGB ë³€í™˜
            if pil_image.mode != 'RGB':
                pil_image = pil_image.convert('RGB')
            
            import numpy as np
            image_np = np.array(pil_image)
            
            # OpenCVë¡œ í‘œ ì…€ ê°ì§€ ì‹œë„
            if HAS_CV2:
                print(f"[OpenCV] í‘œ ì„  ê°ì§€ ì‹œì‘ (ì´ë¯¸ì§€ í¬ê¸°: {image_np.shape[1]}x{image_np.shape[0]})")
                cells = self._detect_table_cells_opencv(image_np)
                if cells:
                    print(f"[OpenCV] ì…€ {len(cells)}ê°œ ê°ì§€ë¨ -> EasyOCRë¡œ ì…€ ë‚´ìš© ì¶”ì¶œ ì¤‘...")
                    opencv_chunks = self._ocr_table_cells(image_np, cells, page_num)
                    if opencv_chunks:
                        print(f"[OpenCV] í‘œ ì¶”ì¶œ ì„±ê³µ!")
                        return opencv_chunks
                    print(f"[OpenCV] ì…€ OCR ì‹¤íŒ¨ -> ê¸°ë³¸ EasyOCR ë°©ì‹ìœ¼ë¡œ ì „í™˜")
                else:
                    print(f"[OpenCV] í‘œ ì„  ê°ì§€ ì‹¤íŒ¨ -> ê¸°ë³¸ EasyOCR ë°©ì‹ìœ¼ë¡œ ì „í™˜")
            else:
                print(f"[EasyOCR] OpenCV ë¹„í™œì„±í™” -> ì¢Œí‘œ ê¸°ë°˜ í‘œ ì¶”ë¡  ë°©ì‹ ì‚¬ìš©")
            
            # OpenCV ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ OCR ë°©ì‹ ì‚¬ìš©
            print(f"[EasyOCR] ì „ì²´ í˜ì´ì§€ OCR ìˆ˜í–‰ ì¤‘...")
            reader = self._get_ocr_reader()
            if not reader:
                print(f"[EasyOCR] OCR ë¦¬ë” ìƒì„± ì‹¤íŒ¨")
                return chunks
            
            # OCR ìˆ˜í–‰ (ì¢Œí‘œ ì •ë³´ í¬í•¨)
            results = reader.readtext(image_np, detail=1, paragraph=False)
            print(f"[EasyOCR] {len(results) if results else 0}ê°œ í…ìŠ¤íŠ¸ ì˜ì—­ ê°ì§€")
            
            if not results:
                return chunks
            
            # ì¢Œí‘œ ê¸°ë°˜ìœ¼ë¡œ í‘œ êµ¬ì¡° ì¶”ë¡ 
            # 1. Yì¢Œí‘œë¡œ ê·¸ë£¹í™” (ê°™ì€ í–‰)
            rows = {}
            for (bbox, text, conf) in results:
                if conf < 0.3:  # ì‹ ë¢°ë„ ë‚®ì€ ê²°ê³¼ ì œì™¸
                    continue
                
                # bbox: [[x1,y1], [x2,y1], [x2,y2], [x1,y2]]
                y_center = (bbox[0][1] + bbox[2][1]) / 2
                x_center = (bbox[0][0] + bbox[2][0]) / 2
                
                # Yì¢Œí‘œë¥¼ 20í”½ì…€ ë‹¨ìœ„ë¡œ ê·¸ë£¹í™” (ê°™ì€ í–‰ìœ¼ë¡œ ì·¨ê¸‰)
                row_key = int(y_center / 20) * 20
                
                if row_key not in rows:
                    rows[row_key] = []
                rows[row_key].append((x_center, text.strip()))
            
            if len(rows) < 2:  # ìµœì†Œ 2í–‰ ì´ìƒì´ì–´ì•¼ í‘œë¡œ ì¸ì‹
                print(f"[EasyOCR] í‘œë¡œ ì¸ì‹í•˜ê¸°ì—” í–‰ì´ ë¶€ì¡± ({len(rows)}í–‰)")
                return chunks
            
            # 2. ê° í–‰ì„ Xì¢Œí‘œë¡œ ì •ë ¬
            sorted_rows = []
            for row_key in sorted(rows.keys()):
                row_cells = sorted(rows[row_key], key=lambda x: x[0])
                row_texts = [cell[1] for cell in row_cells if cell[1]]
                if row_texts:
                    sorted_rows.append(row_texts)
            
            if len(sorted_rows) < 2:
                print(f"[EasyOCR] ì •ë ¬ í›„ í–‰ì´ ë¶€ì¡±")
                return chunks
            
            # 3. Markdown í…Œì´ë¸”ë¡œ ë³€í™˜
            print(f"[EasyOCR] ì¢Œí‘œ ê¸°ë°˜ í‘œ êµ¬ì¡°í™”: {len(sorted_rows)}í–‰ ê°ì§€")
            table_text = self._pdfplumber_table_to_markdown(sorted_rows)
            
            if table_text.strip():
                chunks.append({
                    "text": f"\n\n[ì´ë¯¸ì§€ í‘œ - EasyOCR ì¢Œí‘œ ì¶”ë¡ ]\n{table_text}\n[ì´ë¯¸ì§€ í‘œ ë]\n\n",
                    "page": page_num,
                    "type": "table"
                })
                print(f"[EasyOCR] í‘œ ì¶”ì¶œ ì„±ê³µ! ({len(sorted_rows)}í–‰)")
                # í‘œ ë¯¸ë¦¬ë³´ê¸°
                preview_lines = table_text.split('\n')[:3]
                for line in preview_lines:
                    print(f"    {line}")
        
        except Exception as e:
            print(f"[DocumentProcessor] ì´ë¯¸ì§€ í‘œ OCR ì˜¤ë¥˜ (í˜ì´ì§€ {page_num}): {e}")
        
        return chunks
    
    def _process_pdf_with_pypdf2(self, file_path: Path, chunks: List[Dict]):
        """PyPDF2ë¥¼ ì‚¬ìš©í•œ PDF ì²˜ë¦¬ (Fallback)"""
        with open(file_path, "rb") as f:
                pdf_reader = PyPDF2.PdfReader(f)
                for page_num, page in enumerate(pdf_reader.pages, 1):
                    text = page.extract_text()
                    if text.strip():
                        chunks.append({
                            "text": text.strip(),
                            "page": page_num,
                            "type": "text"
                        })
        
        # ì²­í¬ ë¶„í• 
        return self._chunk_documents(chunks)
    
    def _process_docx(self, file_path: Path) -> List[Dict]:
        """DOCX ì²˜ë¦¬"""
        chunks = []
        doc = Document(file_path)
        
        current_text = ""
        page_num = 1  # DOCXëŠ” ì •í™•í•œ í˜ì´ì§€ ë²ˆí˜¸ê°€ ì—†ìœ¼ë¯€ë¡œ 1ë¡œ ì„¤ì •
        
        for para in doc.paragraphs:
            current_text += para.text + "\n\n"
        
        # í‘œ ì²˜ë¦¬
        for table in doc.tables:
            table_text = self._docx_table_to_markdown(table)
            if current_text.strip():
                chunks.append({
                    "text": current_text.strip(),
                    "page": page_num,
                    "type": "text"
                })
                current_text = ""
            
            chunks.append({
                "text": f"\n\n[í‘œ ì‹œì‘]\n{table_text}\n[í‘œ ë]\n\n",
                "page": page_num,
                "type": "table"
            })
        
        if current_text.strip():
            chunks.append({
                "text": current_text.strip(),
                "page": page_num,
                "type": "text"
            })
        
        return self._chunk_documents(chunks)
    
    def _process_text(self, file_path: Path) -> List[Dict]:
        """í…ìŠ¤íŠ¸ íŒŒì¼ ì²˜ë¦¬"""
        with open(file_path, "r", encoding="utf-8") as f:
            text = f.read()
        
        return self._chunk_documents([{
            "text": text,
            "page": 1,
            "type": "text"
        }])
    
    def _process_image(self, file_path: Path) -> List[Dict]:
        """ì´ë¯¸ì§€ íŒŒì¼ì—ì„œ OCRë¡œ í…ìŠ¤íŠ¸ ì¶”ì¶œ"""
        if not HAS_EASYOCR:
            raise ValueError("EasyOCRì´ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. 'pip install easyocr'ë¡œ ì„¤ì¹˜í•˜ì„¸ìš”.")
        
        if not HAS_PIL:
            raise ValueError("Pillowê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. 'pip install Pillow'ë¡œ ì„¤ì¹˜í•˜ì„¸ìš”.")
        
        chunks = []
        
        try:
            # OCR ë¦¬ë” ê°€ì ¸ì˜¤ê¸° (ì§€ì—° ë¡œë”©)
            reader = self._get_ocr_reader()
            
            # ì´ë¯¸ì§€ ë¡œë“œ
            image = Image.open(file_path)
            
            # RGBë¡œ ë³€í™˜ (í•„ìš”í•œ ê²½ìš°)
            if image.mode != 'RGB':
                image = image.convert('RGB')
            
            print(f"[DocumentProcessor] OCR ì²˜ë¦¬ ì¤‘: {file_path.name}")
            
            # OCR ìˆ˜í–‰
            result = reader.readtext(str(file_path), detail=0, paragraph=True)
            
            # ê²°ê³¼ í…ìŠ¤íŠ¸ í•©ì¹˜ê¸°
            extracted_text = "\n".join(result)
            
            if extracted_text.strip():
                chunks.append({
                    "text": extracted_text.strip(),
                    "page": 1,
                    "type": "ocr"
                })
                print(f"[DocumentProcessor] OCR ì™„ë£Œ: {len(extracted_text)} ê¸€ì ì¶”ì¶œ")
            else:
                print(f"[DocumentProcessor] OCR ê²°ê³¼ ì—†ìŒ: {file_path.name}")
                chunks.append({
                    "text": f"[ì´ë¯¸ì§€ íŒŒì¼: {file_path.name}] - í…ìŠ¤íŠ¸ ì¶”ì¶œ ë¶ˆê°€",
                    "page": 1,
                    "type": "ocr"
                })
        
        except Exception as e:
            print(f"[DocumentProcessor] OCR ì˜¤ë¥˜: {e}")
            chunks.append({
                "text": f"[ì´ë¯¸ì§€ íŒŒì¼: {file_path.name}] - OCR ì²˜ë¦¬ ì˜¤ë¥˜: {str(e)}",
                "page": 1,
                "type": "ocr"
            })
        
        return self._chunk_documents(chunks)
    
    def _process_pdf_with_ocr(self, file_path: Path) -> List[Dict]:
        """PDF í˜ì´ì§€ë¥¼ ì´ë¯¸ì§€ë¡œ ë³€í™˜ í›„ OCR ì²˜ë¦¬ (ìŠ¤ìº” PDFìš©)"""
        if not HAS_PDF2IMAGE:
            raise ValueError("pdf2imageê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. 'pip install pdf2image'ë¡œ ì„¤ì¹˜í•˜ì„¸ìš”.")
        
        if not HAS_EASYOCR:
            raise ValueError("EasyOCRì´ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. 'pip install easyocr'ë¡œ ì„¤ì¹˜í•˜ì„¸ìš”.")
        
        chunks = []
        
        try:
            # OCR ë¦¬ë” ê°€ì ¸ì˜¤ê¸°
            reader = self._get_ocr_reader()
            
            print(f"[DocumentProcessor] PDF OCR ì²˜ë¦¬ ì¤‘: {file_path.name}")
            
            # PDFë¥¼ ì´ë¯¸ì§€ë¡œ ë³€í™˜
            images = convert_from_path(str(file_path), dpi=200)
            
            for page_num, image in enumerate(images, 1):
                print(f"[DocumentProcessor] í˜ì´ì§€ {page_num}/{len(images)} OCR ì²˜ë¦¬ ì¤‘...")
                
                # OCR ìˆ˜í–‰
                import numpy as np
                image_np = np.array(image)
                result = reader.readtext(image_np, detail=0, paragraph=True)
                
                # ê²°ê³¼ í…ìŠ¤íŠ¸ í•©ì¹˜ê¸°
                page_text = "\n".join(result)
                
                if page_text.strip():
                    chunks.append({
                        "text": page_text.strip(),
                        "page": page_num,
                        "type": "ocr"
                    })
            
            print(f"[DocumentProcessor] PDF OCR ì™„ë£Œ: {len(chunks)} í˜ì´ì§€ ì²˜ë¦¬")
        
        except Exception as e:
            print(f"[DocumentProcessor] PDF OCR ì˜¤ë¥˜: {e}")
            # Fallback to PyPDF2
            chunks = []
            self._process_pdf_with_pypdf2(file_path, chunks)
        
        return self._chunk_documents(chunks)
    
    def _process_excel(self, file_path: Path) -> List[Dict]:
        """ì—‘ì…€ íŒŒì¼ ì²˜ë¦¬ (.xlsx, .xls)"""
        chunks = []
        file_ext = file_path.suffix.lower()
        
        if file_ext == ".xlsx" and HAS_OPENPYXL:
            # .xlsx íŒŒì¼ ì²˜ë¦¬
            workbook = openpyxl.load_workbook(file_path, data_only=True)
            
            for sheet_idx, sheet_name in enumerate(workbook.sheetnames, 1):
                sheet = workbook[sheet_name]
                
                # ë³‘í•© ì…€ ì •ë³´ ìˆ˜ì§‘ (Merged Cells Info)
                merged_cells_map = {}
                for merged_range in sheet.merged_cells.ranges:
                    min_row, min_col = merged_range.min_row, merged_range.min_col
                    max_row, max_col = merged_range.max_row, merged_range.max_col
                    
                    # ë³‘í•© ì…€ì˜ ì²« ë²ˆì§¸ ê°’ ê°€ì ¸ì˜¤ê¸°
                    first_cell_value = sheet.cell(min_row, min_col).value
                    first_cell_value = str(first_cell_value) if first_cell_value else ""
                    
                    # ë³‘í•©ëœ ëª¨ë“  ì…€ì— ê°™ì€ ê°’ ë§¤í•‘
                    for r in range(min_row, max_row + 1):
                        for c in range(min_col, max_col + 1):
                            merged_cells_map[(r, c)] = first_cell_value
                
                print(f"[Excel] ì‹œíŠ¸ '{sheet_name}': ë³‘í•© ì…€ {len(sheet.merged_cells.ranges)}ê°œ ê°ì§€")
                
                # ì‹œíŠ¸ì˜ ëª¨ë“  ë°ì´í„°ë¥¼ í‘œë¡œ ì¶”ì¶œ (ë³‘í•© ì…€ ì •ë³´ ì ìš©)
                table_data = []
                for row_idx, row in enumerate(sheet.iter_rows(values_only=True), 1):
                    processed_row = []
                    for col_idx, cell in enumerate(row, 1):
                        # ë³‘í•© ì…€ ì •ë³´ê°€ ìˆìœ¼ë©´ ì‚¬ìš©
                        if (row_idx, col_idx) in merged_cells_map:
                            processed_row.append(merged_cells_map[(row_idx, col_idx)])
                        elif cell is not None:
                            processed_row.append(str(cell))
                        else:
                            processed_row.append("")
                    
                    if any(cell for cell in processed_row):
                        table_data.append(processed_row)
                
                if table_data:
                    # ë§ˆí¬ë‹¤ìš´ í…Œì´ë¸”ë¡œ ë³€í™˜ (ê³„ì¸µí˜• í¬í•¨)
                    table_text = self._excel_table_to_markdown(table_data, sheet_name)
                    chunks.append({
                        "text": f"[ì‹œíŠ¸: {sheet_name}]\n\n[í‘œ ì‹œì‘]\n{table_text}\n[í‘œ ë]",
                        "page": sheet_idx,
                        "type": "table"
                    })
                    
                    # ë¡œê·¸ ì¶œë ¥
                    preview_lines = table_text.split('\n')[:5]
                    print(f"[Excel TABLE] ì‹œíŠ¸ '{sheet_name}': {len(table_data)}í–‰")
                    for line in preview_lines:
                        print(f"    {line}")
            
            workbook.close()
            
        elif file_ext == ".xls" and HAS_XLRD:
            # .xls íŒŒì¼ ì²˜ë¦¬
            workbook = xlrd.open_workbook(file_path)
            
            for sheet_idx in range(workbook.nsheets):
                sheet = workbook.sheet_by_index(sheet_idx)
                sheet_name = sheet.name
                
                # ì‹œíŠ¸ì˜ ëª¨ë“  ë°ì´í„°ë¥¼ í‘œë¡œ ì¶”ì¶œ
                table_data = []
                for row_idx in range(sheet.nrows):
                    row = [str(sheet.cell_value(row_idx, col_idx)) for col_idx in range(sheet.ncols)]
                    if any(cell for cell in row):
                        table_data.append(row)
                
                if table_data:
                    # ë§ˆí¬ë‹¤ìš´ í…Œì´ë¸”ë¡œ ë³€í™˜
                    table_text = self._excel_table_to_markdown(table_data, sheet_name)
                    chunks.append({
                        "text": f"[ì‹œíŠ¸: {sheet_name}]\n\n[í‘œ ì‹œì‘]\n{table_text}\n[í‘œ ë]",
                        "page": sheet_idx + 1,
                        "type": "table"
                    })
        else:
            raise ValueError(f"Excel file processing not available for {file_ext}")
        
        print(f"[DocumentProcessor] Excel ì²˜ë¦¬ ì™„ë£Œ: {len(chunks)} ì‹œíŠ¸")
        return self._chunk_documents(chunks)
    
    def _excel_table_to_markdown(self, table_data: List[List], sheet_name: str = "") -> str:
        """ì—‘ì…€ í…Œì´ë¸” ë°ì´í„°ë¥¼ ê³„ì¸µí˜• í…ìŠ¤íŠ¸ + ë§ˆí¬ë‹¤ìš´ í˜•ì‹ìœ¼ë¡œ ë³€í™˜"""
        if not table_data:
            return ""
        
        # ìµœëŒ€ ì—´ ìˆ˜ ê³„ì‚°
        max_cols = max(len(row) for row in table_data)
        
        # ëª¨ë“  í–‰ì„ ê°™ì€ ì—´ ìˆ˜ë¡œ ë§ì¶”ê¸°
        for row in table_data:
            while len(row) < max_cols:
                row.append("")
        
        # ====== Column-wise Forward Fill (ì—´ ë‹¨ìœ„ ì±„ìš°ê¸°) ======
        for col_idx in range(max_cols):
            last_value = ""
            for row_idx in range(len(table_data)):
                cell_value = table_data[row_idx][col_idx].strip()
                if cell_value:
                    last_value = cell_value
                elif last_value and row_idx > 0:
                    # ë¹ˆ ì…€: ìœ„ìª½ ê°’ìœ¼ë¡œ ì±„ì›€ (Fill-down)
                    table_data[row_idx][col_idx] = last_value
        
        # ë¹ˆ ì—´ ì œê±° (ëª¨ë“  í–‰ì—ì„œ ë¹ˆ ì—´)
        cols_to_keep = []
        for col_idx in range(max_cols):
            if any(row[col_idx].strip() for row in table_data):
                cols_to_keep.append(col_idx)
        
        if cols_to_keep:
            table_data = [[row[col_idx] for col_idx in cols_to_keep] for row in table_data]
            max_cols = len(cols_to_keep)
        
        output_lines = []
        
        # í—¤ë” í–‰
        headers = table_data[0] if table_data else []
        for i, h in enumerate(headers):
            if not h.strip():
                headers[i] = f"ì—´{i+1}"
        
        # ====== ê³„ì¸µí˜• í…ìŠ¤íŠ¸ ìƒì„± (Hierarchical Text Construction) ======
        output_lines.append("[ê³„ì¸µí˜• ë°ì´í„°]")
        
        for row in table_data[1:]:
            hierarchy_parts = []
            value_parts = []
            
            for col_idx, cell in enumerate(row):
                if not cell.strip():
                    continue
                    
                header = headers[col_idx] if col_idx < len(headers) else f"ì—´{col_idx+1}"
                
                # ë§ˆì§€ë§‰ 2ì—´ ë˜ëŠ” ìˆ«ì/ê¸ˆì•¡ì´ í¬í•¨ëœ ì—´ì€ ê°’ìœ¼ë¡œ ì²˜ë¦¬
                is_value = (col_idx >= len(row) - 2) or \
                           any(c.isdigit() for c in cell) or \
                           any(unit in cell for unit in ['ì›', '%', 'ê°œ', 'ê±´', 'ëª…', 'ì¼', 'ì‹œê°„'])
                
                if is_value and hierarchy_parts:
                    value_parts.append(f"{header}: {cell}")
                else:
                    hierarchy_parts.append(cell)
            
            if hierarchy_parts or value_parts:
                if hierarchy_parts and value_parts:
                    hierarchy_str = " > ".join(hierarchy_parts)
                    value_str = ", ".join(value_parts)
                    output_lines.append(f"  - {hierarchy_str} >> {value_str}")
                elif hierarchy_parts:
                    output_lines.append(f"  - " + " > ".join(hierarchy_parts))
                elif value_parts:
                    output_lines.append(f"  - " + ", ".join(value_parts))
        
        output_lines.append("")
        
        # ====== Markdown Table (ì°¸ì¡°ìš©) ======
        output_lines.append("[í‘œ ì›ë³¸]")
        output_lines.append("| " + " | ".join(headers) + " |")
        output_lines.append("| " + " | ".join(["---"] * max_cols) + " |")
        
        for row in table_data[1:]:
            escaped_row = [cell.replace("|", "\\|") for cell in row]
            output_lines.append("| " + " | ".join(escaped_row) + " |")
        
        return "\n".join(output_lines)
    
    def _table_to_markdown(self, table_text: str) -> str:
        """í‘œ í…ìŠ¤íŠ¸ë¥¼ ë§ˆí¬ë‹¤ìš´ í˜•ì‹ìœ¼ë¡œ ë³€í™˜"""
        lines = table_text.strip().split("\n")
        if not lines:
            return ""
        
        if len(lines) < 2:
            return table_text
        
        # ê° í–‰ì„ ì…€ë¡œ ë¶„ë¦¬
        all_rows = []
        max_cols = 0
        
        for line in lines:
            # íƒ­ìœ¼ë¡œ ë¶„ë¦¬ ì‹œë„
            cells = [c.strip() for c in line.split("\t")]
            if len(cells) == 1:
                # íƒ­ì´ ì—†ìœ¼ë©´ ì—¬ëŸ¬ ê³µë°±ìœ¼ë¡œ ë¶„ë¦¬
                cells = [c.strip() for c in line.split("  ") if c.strip()]
            if not cells:
                cells = [line.strip()]
            
            all_rows.append(cells)
            max_cols = max(max_cols, len(cells))
        
        if max_cols == 0:
            return table_text
        
        # ëª¨ë“  í–‰ì„ ê°™ì€ ì—´ ìˆ˜ë¡œ ë§ì¶”ê¸°
        for row in all_rows:
            while len(row) < max_cols:
                row.append("")
        
        # ë§ˆí¬ë‹¤ìš´ í…Œì´ë¸” ìƒì„±
        md_lines = []
        
        # í—¤ë” í–‰
        md_lines.append("| " + " | ".join(all_rows[0]) + " |")
        
        # êµ¬ë¶„ì„ 
        md_lines.append("| " + " | ".join(["---"] * max_cols) + " |")
        
        # ë°ì´í„° í–‰
        for row in all_rows[1:]:
            md_lines.append("| " + " | ".join(row) + " |")
        
        return "\n".join(md_lines)
    
    def _docx_table_to_markdown(self, table) -> str:
        """DOCX í‘œë¥¼ ë§ˆí¬ë‹¤ìš´ í˜•ì‹ìœ¼ë¡œ ë³€í™˜"""
        md_lines = []
        max_cols = 0
        
        # ëª¨ë“  í–‰ ìˆ˜ì§‘ ë° ìµœëŒ€ ì—´ ìˆ˜ ê³„ì‚°
        all_rows = []
        for row in table.rows:
            cells = [cell.text.strip() for cell in row.cells]
            all_rows.append(cells)
            max_cols = max(max_cols, len(cells))
        
        if not all_rows:
            return ""
        
        # ëª¨ë“  í–‰ì„ ê°™ì€ ì—´ ìˆ˜ë¡œ ë§ì¶”ê¸°
        for row in all_rows:
            while len(row) < max_cols:
                row.append("")
        
        # í—¤ë” í–‰
        md_lines.append("| " + " | ".join(all_rows[0]) + " |")
        
        # êµ¬ë¶„ì„ 
        md_lines.append("| " + " | ".join(["---"] * max_cols) + " |")
        
        # ë°ì´í„° í–‰
        for row in all_rows[1:]:
            md_lines.append("| " + " | ".join(row) + " |")
        
        return "\n".join(md_lines)
    
    def _chunk_documents(self, chunks: List[Dict]) -> List[Dict]:
        """ë¬¸ì„œë¥¼ ì§€ì •ëœ í¬ê¸°ë¡œ ì²­í¬ ë¶„í• 
        
        í‘œ(table) ì²­í¬ëŠ” ë¶„í• í•˜ì§€ ì•Šê³  ì˜¨ì „íˆ í•˜ë‚˜ì˜ ì²­í¬ë¡œ ìœ ì§€
        has_table ë©”íƒ€ë°ì´í„°ë¡œ í‘œ í¬í•¨ ì—¬ë¶€ í‘œì‹œ
        """
        final_chunks = []
        
        # í‘œ ì²­í¬ ìµœëŒ€ í¬ê¸° (í‘œëŠ” ì¼ë°˜ í…ìŠ¤íŠ¸ë³´ë‹¤ í¬ê²Œ í—ˆìš©)
        TABLE_MAX_SIZE = self.chunk_size * 3  # í‘œëŠ” 3ë°° í¬ê¸°ê¹Œì§€ í—ˆìš©
        
        for chunk in chunks:
            text = chunk["text"]
            page = chunk["page"]
            chunk_type = chunk["type"]
            is_table = chunk_type == "table"
            
            # ====== í‘œ ì²­í¬: ë¶„í• í•˜ì§€ ì•Šê³  ì˜¨ì „íˆ ìœ ì§€ ======
            if is_table:
                # í‘œëŠ” ê°€ê¸‰ì  ë¶„í• í•˜ì§€ ì•ŠìŒ (ë§¤ìš° í° í‘œë§Œ ì˜ˆì™¸ì ìœ¼ë¡œ ë¶„í• )
                if len(text) <= TABLE_MAX_SIZE:
                    final_chunks.append({
                        "text": text,
                        "page": page,
                        "type": chunk_type,
                        "metadata": {
                            "page": page, 
                            "type": chunk_type,
                            "has_table": True  # í‘œ í¬í•¨ íƒœê·¸
                        }
                    })
                else:
                    # ë§¤ìš° í° í‘œ: í–‰ ë‹¨ìœ„ë¡œ ë¶„í•  (Markdown í…Œì´ë¸” êµ¬ì¡° ìœ ì§€)
                    lines = text.split("\n")
                    header_lines = []
                    data_lines = []
                    
                    # í—¤ë”ì™€ êµ¬ë¶„ì„  ì¶”ì¶œ
                    for i, line in enumerate(lines):
                        if i < 3 and (line.startswith("|") or "---" in line or "[í‘œ" in line):
                            header_lines.append(line)
                        else:
                            data_lines.append(line)
                    
                    header_text = "\n".join(header_lines)
                    current_chunk_lines = []
                    current_length = len(header_text)
                    
                    for line in data_lines:
                        if current_length + len(line) > self.chunk_size and current_chunk_lines:
                            # í˜„ì¬ ì²­í¬ ì €ì¥ (í—¤ë” í¬í•¨)
                            chunk_text = header_text + "\n" + "\n".join(current_chunk_lines)
                            final_chunks.append({
                                "text": chunk_text,
                                "page": page,
                                "type": chunk_type,
                                "metadata": {
                                    "page": page, 
                                    "type": chunk_type,
                                    "has_table": True,
                                    "table_continued": True  # ì´ì–´ì§€ëŠ” í‘œì„ì„ í‘œì‹œ
                                }
                            })
                            current_chunk_lines = [line]
                            current_length = len(header_text) + len(line)
                        else:
                            current_chunk_lines.append(line)
                            current_length += len(line) + 1
                    
                    # ë§ˆì§€ë§‰ ì²­í¬
                    if current_chunk_lines:
                        chunk_text = header_text + "\n" + "\n".join(current_chunk_lines)
                        final_chunks.append({
                            "text": chunk_text,
                            "page": page,
                            "type": chunk_type,
                            "metadata": {
                                "page": page, 
                                "type": chunk_type,
                                "has_table": True
                            }
                        })
            
            # ====== ì¼ë°˜ í…ìŠ¤íŠ¸ ì²­í¬ ======
            elif len(text) <= self.chunk_size:
                final_chunks.append({
                    "text": text,
                    "page": page,
                    "type": chunk_type,
                    "metadata": {
                        "page": page, 
                        "type": chunk_type,
                        "has_table": False
                    }
                })
            else:
                # í…ìŠ¤íŠ¸ë¥¼ ë” ì‘ì€ ì²­í¬ë¡œ ë¶„í• 
                words = text.split()
                current_chunk = []
                current_length = 0
                
                for word in words:
                    word_length = len(word) + 1
                    if current_length + word_length > self.chunk_size and current_chunk:
                        chunk_text = " ".join(current_chunk)
                        final_chunks.append({
                            "text": chunk_text,
                            "page": page,
                            "type": chunk_type,
                            "metadata": {
                                "page": page, 
                                "type": chunk_type,
                                "has_table": False
                            }
                        })
                        # Overlapì„ ìœ„í•´ ë§ˆì§€ë§‰ ë¶€ë¶„ ìœ ì§€
                        overlap_size = int(self.chunk_overlap / 10)
                        current_chunk = current_chunk[-overlap_size:] + [word]
                        current_length = sum(len(w) + 1 for w in current_chunk)
                    else:
                        current_chunk.append(word)
                        current_length += word_length
                
                # ë§ˆì§€ë§‰ ì²­í¬
                if current_chunk:
                    chunk_text = " ".join(current_chunk)
                    final_chunks.append({
                        "text": chunk_text,
                        "page": page,
                        "type": chunk_type,
                        "metadata": {
                            "page": page, 
                            "type": chunk_type,
                            "has_table": False
                        }
                    })
        
        # í†µê³„ ë¡œê¹…
        table_chunks = sum(1 for c in final_chunks if c["metadata"].get("has_table"))
        text_chunks = len(final_chunks) - table_chunks
        print(f"[DocumentProcessor] ì²­í‚¹ ì™„ë£Œ: í…ìŠ¤íŠ¸ {text_chunks}ê°œ, í‘œ {table_chunks}ê°œ")
        
        return final_chunks

