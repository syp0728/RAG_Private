# ğŸ—ï¸ Private RAG ì‹œìŠ¤í…œ ìŠ¤ìºí´ë”© ê°€ì´ë“œ

> ì†ŒìŠ¤ì½”ë“œ ì—†ì´ ì²˜ìŒë¶€í„° í”„ë¡œì íŠ¸ë¥¼ ì§ì ‘ êµ¬ì¶•í•˜ëŠ” ì™„ì „ ê°€ì´ë“œ

---

## ğŸ“‹ ëª©ì°¨

1. [ê°œìš”](#1-ê°œìš”)
2. [ì‚¬ì „ ì¤€ë¹„](#2-ì‚¬ì „-ì¤€ë¹„)
3. [í”„ë¡œì íŠ¸ êµ¬ì¡° ìƒì„±](#3-í”„ë¡œì íŠ¸-êµ¬ì¡°-ìƒì„±)
4. [ë°±ì—”ë“œ êµ¬í˜„](#4-ë°±ì—”ë“œ-êµ¬í˜„)
5. [í”„ë¡ íŠ¸ì—”ë“œ êµ¬í˜„](#5-í”„ë¡ íŠ¸ì—”ë“œ-êµ¬í˜„)
6. [AI ëª¨ë¸ ì„¤ì •](#6-ai-ëª¨ë¸-ì„¤ì •)
7. [ì‹¤í–‰ ë° í…ŒìŠ¤íŠ¸](#7-ì‹¤í–‰-ë°-í…ŒìŠ¤íŠ¸)

---

## 1. ê°œìš”

### ì´ ê°€ì´ë“œì˜ ëª©ì 

ì†ŒìŠ¤ì½”ë“œê°€ ì „í˜€ ì—†ëŠ” ìƒíƒœì—ì„œ Private RAG ì‹œìŠ¤í…œì„ ì²˜ìŒë¶€í„° êµ¬ì¶•í•˜ëŠ” ë°©ë²•ì„ ì•ˆë‚´í•©ë‹ˆë‹¤.

### ìµœì¢… ê²°ê³¼ë¬¼

```
RAG_Private/
â”œâ”€â”€ backend/           # Python Flask API ì„œë²„
â”‚   â”œâ”€â”€ app.py
â”‚   â”œâ”€â”€ config.py
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â””â”€â”€ core/
â”‚       â”œâ”€â”€ rag_system.py
â”‚       â”œâ”€â”€ document_processor.py
â”‚       â”œâ”€â”€ file_manager.py
â”‚       â””â”€â”€ filename_parser.py
â”œâ”€â”€ frontend/          # React + Vite ì›¹ UI
â”‚   â”œâ”€â”€ package.json
â”‚   â”œâ”€â”€ vite.config.js
â”‚   â””â”€â”€ src/
â”‚       â”œâ”€â”€ App.jsx
â”‚       â””â”€â”€ components/
â”œâ”€â”€ data/              # ë°ì´í„° ì €ì¥ì†Œ
â”‚   â”œâ”€â”€ uploads/
â”‚   â””â”€â”€ chroma_db/
â””â”€â”€ models/            # AI ëª¨ë¸ ìºì‹œ
```

---

## 2. ì‚¬ì „ ì¤€ë¹„

### 2.1 í•„ìˆ˜ ì†Œí”„íŠ¸ì›¨ì–´ ì„¤ì¹˜

| ì†Œí”„íŠ¸ì›¨ì–´ | ë²„ì „ | ë‹¤ìš´ë¡œë“œ |
|-----------|------|----------|
| Python | 3.11.x | https://www.python.org/downloads/release/python-3119/ |
| Node.js | 18+ LTS | https://nodejs.org/ |
| Ollama | ìµœì‹  | https://ollama.com/download |

> âš ï¸ **ì¤‘ìš”**: Python ì„¤ì¹˜ ì‹œ "Add Python to PATH" ë°˜ë“œì‹œ ì²´í¬!

### 2.2 ì„¤ì¹˜ í™•ì¸

```powershell
python --version   # Python 3.11.x
node --version     # v18.x.x ì´ìƒ
npm --version      # 9.x.x ì´ìƒ
ollama --version   # ollama version 0.x.x
```

---

## 3. í”„ë¡œì íŠ¸ êµ¬ì¡° ìƒì„±

### 3.1 ë£¨íŠ¸ í´ë” ìƒì„±

```powershell
# ì‘ì—… ìœ„ì¹˜ë¡œ ì´ë™
cd C:\Users\ì‚¬ìš©ìì´ë¦„\Documents

# í”„ë¡œì íŠ¸ í´ë” ìƒì„±
mkdir RAG_Private
cd RAG_Private

# í•˜ìœ„ í´ë” ìƒì„±
mkdir backend
mkdir backend\core
mkdir frontend
mkdir frontend\src
mkdir frontend\src\components
mkdir frontend\src\services
mkdir data
mkdir data\uploads
mkdir data\chroma_db
mkdir models
mkdir docs
```

### 3.2 í´ë” êµ¬ì¡° í™•ì¸

```
RAG_Private/
â”œâ”€â”€ backend/
â”‚   â””â”€â”€ core/
â”œâ”€â”€ frontend/
â”‚   â””â”€â”€ src/
â”‚       â”œâ”€â”€ components/
â”‚       â””â”€â”€ services/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ uploads/
â”‚   â””â”€â”€ chroma_db/
â”œâ”€â”€ models/
â””â”€â”€ docs/
```

---

## 4. ë°±ì—”ë“œ êµ¬í˜„

### 4.1 ê°€ìƒí™˜ê²½ ìƒì„±

```powershell
cd backend
python -m venv venv311
.\venv311\Scripts\Activate.ps1
```

### 4.2 requirements.txt ì‘ì„±

```powershell
# backend/requirements.txt ìƒì„±
```

**íŒŒì¼: `backend/requirements.txt`**
```text
flask==3.0.0
flask-cors==4.0.0
langchain==0.1.0
langchain-community==0.0.10
chromadb==0.4.22
sentence-transformers==2.3.1
ollama==0.1.7
pypdf2==3.0.1
python-docx==1.1.0
python-multipart==0.0.6
werkzeug==3.0.1

# PDF í‘œ ì¶”ì¶œ
pdfplumber>=0.10.0
pillow>=10.0.0

# ì—‘ì…€ íŒŒì¼ ì²˜ë¦¬
openpyxl>=3.1.0
xlrd>=2.0.0

# ì´ë¯¸ì§€ ì²˜ë¦¬ ë° OCR
opencv-python-headless>=4.8.0
easyocr>=1.7.0
numpy>=1.24.0

# ê²€ìƒ‰ ì—”ì§„
rank_bm25>=0.2.2
```

### 4.3 íŒ¨í‚¤ì§€ ì„¤ì¹˜

```powershell
pip install --upgrade pip
pip install -r requirements.txt
```

---

### 4.4 config.py ì‘ì„±

**íŒŒì¼: `backend/config.py`**
```python
import os
from pathlib import Path

# ê¸°ë³¸ ë””ë ‰í† ë¦¬ ì„¤ì •
BASE_DIR = Path(__file__).parent.parent
DATA_DIR = BASE_DIR / "data"
MODELS_DIR = BASE_DIR / "models"
UPLOAD_DIR = DATA_DIR / "uploads"
VECTOR_DB_DIR = DATA_DIR / "chroma_db"

# ë””ë ‰í† ë¦¬ ìƒì„±
for dir_path in [DATA_DIR, MODELS_DIR, UPLOAD_DIR, VECTOR_DB_DIR]:
    dir_path.mkdir(parents=True, exist_ok=True)

# Ollama ì„¤ì •
OLLAMA_BASE_URL = os.getenv("OLLAMA_BASE_URL", "http://localhost:11434")
OLLAMA_MODEL = "llama3.1:8b-instruct-q4_K_M"

# ì„ë² ë”© ì„¤ì • (CPUì—ì„œ ì‹¤í–‰)
EMBEDDING_MODEL = "BAAI/bge-m3"
EMBEDDING_DEVICE = "cpu"

# ChromaDB ì„¤ì •
CHROMA_COLLECTION_NAME = "enterprise_documents"
CHROMA_PERSIST_DIR = str(VECTOR_DB_DIR)

# íŒŒì¼ ì—…ë¡œë“œ ì„¤ì •
MAX_FILE_SIZE = 50 * 1024 * 1024  # 50MB
ALLOWED_EXTENSIONS = {
    ".pdf", ".docx", ".txt", ".md", ".xlsx", ".xls",
    ".png", ".jpg", ".jpeg", ".gif", ".bmp", ".tiff", ".tif", ".webp"
}

# RAG ì„¤ì •
TOP_K_RESULTS = 40
CHUNK_SIZE = 1000
CHUNK_OVERLAP = 200

# ì»¨í…ìŠ¤íŠ¸ êµ¬ì„± ì„¤ì •
MAX_CHUNKS_PER_FILE = 15
MIN_CONTEXT_COUNT = 15
MAX_CONTEXT_COUNT = 30

# í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ê°€ì¤‘ì¹˜
VECTOR_WEIGHT = 0.4
BM25_WEIGHT = 0.6

# ì¬ìˆœìœ„í™” ì„¤ì •
RERANK_TOP_K = 25
RERANK_ENABLED = True

# ì—”í‹°í‹° ì¶”ì¶œ ì„¤ì •
ENTITY_EXTRACTION_ENABLED = True
ENTITY_EXTRACTION_BATCH_SIZE = 5
ENTITY_TYPES = [
    "person", "organization", "date_value", 
    "money", "location", "product", "keyword"
]
```

---

### 4.5 core/filename_parser.py ì‘ì„±

**íŒŒì¼: `backend/core/filename_parser.py`**
```python
"""íŒŒì¼ëª… íŒŒì‹± ìœ í‹¸ë¦¬í‹°"""
import re
from typing import Dict, Optional

def parse_filename(filename: str) -> Dict[str, Optional[str]]:
    """
    íŒŒì¼ëª…ì„ íŒŒì‹±í•˜ì—¬ ë©”íƒ€ë°ì´í„° ì¶”ì¶œ
    í˜•ì‹: YYMMDD_ë¬¸ì„œìœ í˜•_ë¬¸ì„œì œëª©.í™•ì¥ì
    
    ì˜ˆì‹œ:
    - "250211_ì¬ì§ì¦ëª…ì„œ_ì„¼ì‹±í”ŒëŸ¬ìŠ¤.pdf" 
      -> {"date": "250211", "doc_type": "ì¬ì§ì¦ëª…ì„œ", "doc_title": "ì„¼ì‹±í”ŒëŸ¬ìŠ¤"}
    """
    # í™•ì¥ì ì œê±°
    name_without_ext = filename.rsplit('.', 1)[0] if '.' in filename else filename
    
    # íŒ¨í„´: (ë‚ ì§œ 6ìë¦¬)_(ë¬¸ì„œìœ í˜•)_(ë¬¸ì„œì œëª©)
    pattern = r'^(\d{6})_(.+?)_(.+)$'
    match = re.match(pattern, name_without_ext)
    
    if match:
        return {
            "date": match.group(1),
            "doc_type": match.group(2),
            "doc_title": match.group(3),
            "parsed": True
        }
    else:
        return {
            "date": None,
            "doc_type": None,
            "doc_title": None,
            "parsed": False
        }

def format_date(date_str: str) -> str:
    """ë‚ ì§œ ë¬¸ìì—´ì„ ì½ê¸° ì‰¬ìš´ í˜•ì‹ìœ¼ë¡œ ë³€í™˜"""
    if not date_str or len(date_str) != 6:
        return date_str
    
    try:
        year = "20" + date_str[:2]
        month = date_str[2:4]
        day = date_str[4:6]
        return f"{year}ë…„ {month}ì›” {day}ì¼"
    except:
        return date_str
```

---

### 4.6 core/file_manager.py ì‘ì„±

**íŒŒì¼: `backend/core/file_manager.py`**
```python
import hashlib
import json
from pathlib import Path
from config import UPLOAD_DIR
from .filename_parser import parse_filename

class FileManager:
    """íŒŒì¼ ì—…ë¡œë“œ ë° ë‹¤ìš´ë¡œë“œ ê´€ë¦¬"""
    
    def __init__(self):
        self.upload_dir = UPLOAD_DIR
        self.file_registry = {}
        self.metadata_file = self.upload_dir / ".file_metadata.json"
        self._load_metadata()
    
    def _generate_file_id(self, filename):
        """íŒŒì¼ ID ìƒì„± (í•´ì‹œ ê¸°ë°˜)"""
        return hashlib.md5(filename.encode()).hexdigest()
    
    def _load_metadata(self):
        """ë©”íƒ€ë°ì´í„° íŒŒì¼ì—ì„œ ì›ë³¸ íŒŒì¼ëª… ì •ë³´ ë¡œë“œ"""
        if self.metadata_file.exists():
            try:
                with open(self.metadata_file, 'r', encoding='utf-8') as f:
                    metadata = json.load(f)
                    for file_id, info in metadata.items():
                        safe_filename = info.get('safe_filename', '')
                        file_path = self.upload_dir / f"{file_id}_{safe_filename}"
                        if file_path.exists():
                            self.file_registry[file_id] = {
                                "id": file_id,
                                "filename": info.get('original_filename', safe_filename),
                                "path": file_path,
                                "size": file_path.stat().st_size
                            }
            except Exception as e:
                print(f"ë©”íƒ€ë°ì´í„° ë¡œë“œ ì˜¤ë¥˜: {e}")
    
    def _save_metadata(self):
        """ë©”íƒ€ë°ì´í„° íŒŒì¼ì— ì›ë³¸ íŒŒì¼ëª… ì •ë³´ ì €ì¥"""
        metadata = {}
        for file_id, info in self.file_registry.items():
            if info["path"].exists():
                parsed_info = parse_filename(info["filename"])
                file_metadata = {
                    "original_filename": info["filename"],
                    "safe_filename": info["path"].name.split("_", 1)[1] if "_" in info["path"].name else info["path"].name
                }
                if parsed_info["parsed"]:
                    file_metadata.update({
                        "date": parsed_info["date"],
                        "doc_type": parsed_info["doc_type"],
                        "doc_title": parsed_info["doc_title"]
                    })
                metadata[file_id] = file_metadata
        
        try:
            with open(self.metadata_file, 'w', encoding='utf-8') as f:
                json.dump(metadata, f, ensure_ascii=False, indent=2)
        except Exception as e:
            print(f"ë©”íƒ€ë°ì´í„° ì €ì¥ ì˜¤ë¥˜: {e}")
    
    def save_file(self, file, safe_filename, original_filename=None):
        """íŒŒì¼ ì €ì¥ ë° ID ë°˜í™˜"""
        if original_filename is None:
            original_filename = safe_filename
        
        file_id = self._generate_file_id(original_filename)
        file_path = self.upload_dir / f"{file_id}_{safe_filename}"
        
        file.save(str(file_path))
        
        self.file_registry[file_id] = {
            "id": file_id,
            "filename": original_filename,
            "path": file_path,
            "size": file_path.stat().st_size
        }
        
        self._save_metadata()
        return file_path
    
    def get_file_path(self, file_id):
        """íŒŒì¼ IDë¡œ íŒŒì¼ ê²½ë¡œ ì¡°íšŒ"""
        if file_id in self.file_registry:
            return self.file_registry[file_id]["path"]
        
        for file_path in self.upload_dir.glob(f"{file_id}_*"):
            return file_path
        return None
    
    def list_files(self):
        """ì—…ë¡œë“œëœ íŒŒì¼ ëª©ë¡ ë°˜í™˜"""
        files = []
        for file_id, file_info in self.file_registry.items():
            if file_info["path"].exists():
                files.append({
                    "id": file_id,
                    "filename": file_info["filename"],
                    "size": file_info["size"]
                })
        return files
    
    def delete_file(self, file_id):
        """íŒŒì¼ ì‚­ì œ"""
        file_path = self.get_file_path(file_id)
        if file_path and file_path.exists():
            file_path.unlink()
            if file_id in self.file_registry:
                del self.file_registry[file_id]
            self._save_metadata()
            return True
        return False
```

---

### 4.7 core/logger.py ì‘ì„±

**íŒŒì¼: `backend/core/logger.py`**
```python
"""ì»¬ëŸ¬ ë¡œê¹… ìœ í‹¸ë¦¬í‹°"""
from datetime import datetime

class Logger:
    """í„°ë¯¸ë„ ì»¬ëŸ¬ ë¡œê±°"""
    
    # ANSI ìƒ‰ìƒ ì½”ë“œ
    COLORS = {
        'reset': '\033[0m',
        'red': '\033[91m',
        'green': '\033[92m',
        'yellow': '\033[93m',
        'blue': '\033[94m',
        'purple': '\033[95m',
        'cyan': '\033[96m',
        'white': '\033[97m',
    }
    
    def _log(self, level: str, color: str, tag: str, message: str):
        timestamp = datetime.now().strftime('%H:%M:%S')
        color_code = self.COLORS.get(color, self.COLORS['white'])
        reset = self.COLORS['reset']
        print(f"{color_code}[{timestamp}] [{tag}] {message}{reset}")
    
    def info(self, tag: str, message: str):
        self._log('INFO', 'cyan', tag, message)
    
    def success(self, tag: str, message: str):
        self._log('SUCCESS', 'green', tag, message)
    
    def warning(self, tag: str, message: str):
        self._log('WARNING', 'yellow', tag, message)
    
    def error(self, tag: str, message: str):
        self._log('ERROR', 'red', tag, message)

logger = Logger()
```

---

### 4.8 core/__init__.py ì‘ì„±

**íŒŒì¼: `backend/core/__init__.py`**
```python
# core íŒ¨í‚¤ì§€ ì´ˆê¸°í™”
```

---

### 4.9 core/document_processor.py ì‘ì„± (í•µì‹¬)

> âš ï¸ ì´ íŒŒì¼ì€ ë§¤ìš° ê¸¸ê¸° ë•Œë¬¸ì— í•µì‹¬ êµ¬ì¡°ë§Œ ì œì‹œí•©ë‹ˆë‹¤.

**íŒŒì¼: `backend/core/document_processor.py`**
```python
"""ë¬¸ì„œ ì²˜ë¦¬ ëª¨ë“ˆ - PDF, DOCX, Excel íŒŒì‹±"""
import os
from pathlib import Path
from typing import List, Dict, Any

class DocumentProcessor:
    """ë¬¸ì„œ íŒŒì‹± ë° ì²­í‚¹ ì²˜ë¦¬"""
    
    def __init__(self, chunk_size: int = 1000, chunk_overlap: int = 200):
        self.chunk_size = chunk_size
        self.chunk_overlap = chunk_overlap
        self.ocr_reader = None  # EasyOCR (ì§€ì—° ë¡œë”©)
    
    def process(self, file_path: str, filename: str = None) -> List[Dict[str, Any]]:
        """íŒŒì¼ì„ ì²˜ë¦¬í•˜ì—¬ ì²­í¬ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜"""
        path = Path(file_path)
        ext = path.suffix.lower()
        
        if filename is None:
            filename = path.name
        
        # íŒŒì¼ í˜•ì‹ë³„ ì²˜ë¦¬
        if ext == '.pdf':
            return self._process_pdf(path, filename)
        elif ext == '.docx':
            return self._process_docx(path, filename)
        elif ext in ['.xlsx', '.xls']:
            return self._process_excel(path, filename)
        elif ext == '.txt':
            return self._process_text(path, filename)
        elif ext in ['.png', '.jpg', '.jpeg']:
            return self._process_image(path, filename)
        else:
            raise ValueError(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹: {ext}")
    
    def _process_pdf(self, path: Path, filename: str) -> List[Dict]:
        """PDF íŒŒì¼ ì²˜ë¦¬"""
        from .logger import logger
        import pdfplumber
        
        chunks = []
        logger.info("PDF", f"Processing: {filename}")
        
        with pdfplumber.open(str(path)) as pdf:
            for page_num, page in enumerate(pdf.pages, 1):
                # í…ìŠ¤íŠ¸ ì¶”ì¶œ
                text = page.extract_text() or ""
                
                # í‘œ ì¶”ì¶œ
                tables = page.extract_tables()
                if tables:
                    logger.info("PDF", f"Page {page_num}: {len(tables)} tables found")
                    for table in tables:
                        table_text = self._table_to_markdown(table)
                        if table_text:
                            chunks.append({
                                "text": table_text,
                                "page": page_num,
                                "type": "table",
                                "metadata": {"has_table": True}
                            })
                
                # ì¼ë°˜ í…ìŠ¤íŠ¸ ì²­í‚¹
                if text.strip():
                    text_chunks = self._chunk_text(text, page_num)
                    chunks.extend(text_chunks)
        
        logger.success("PDF", f"Total chunks: {len(chunks)}")
        return chunks
    
    def _process_docx(self, path: Path, filename: str) -> List[Dict]:
        """DOCX íŒŒì¼ ì²˜ë¦¬"""
        from docx import Document
        
        doc = Document(str(path))
        full_text = "\n".join([p.text for p in doc.paragraphs if p.text.strip()])
        return self._chunk_text(full_text, page=1)
    
    def _process_excel(self, path: Path, filename: str) -> List[Dict]:
        """Excel íŒŒì¼ ì²˜ë¦¬"""
        import openpyxl
        
        chunks = []
        wb = openpyxl.load_workbook(str(path), data_only=True)
        
        for sheet_name in wb.sheetnames:
            sheet = wb[sheet_name]
            table_data = []
            
            for row in sheet.iter_rows(values_only=True):
                if any(cell is not None for cell in row):
                    table_data.append([str(cell) if cell else "" for cell in row])
            
            if table_data:
                markdown = self._table_to_markdown(table_data)
                chunks.append({
                    "text": f"[ì‹œíŠ¸: {sheet_name}]\n{markdown}",
                    "page": 1,
                    "type": "table",
                    "metadata": {"has_table": True, "sheet": sheet_name}
                })
        
        return chunks
    
    def _process_text(self, path: Path, filename: str) -> List[Dict]:
        """í…ìŠ¤íŠ¸ íŒŒì¼ ì²˜ë¦¬"""
        with open(path, 'r', encoding='utf-8') as f:
            text = f.read()
        return self._chunk_text(text, page=1)
    
    def _process_image(self, path: Path, filename: str) -> List[Dict]:
        """ì´ë¯¸ì§€ íŒŒì¼ OCR ì²˜ë¦¬"""
        if self.ocr_reader is None:
            import easyocr
            self.ocr_reader = easyocr.Reader(['ko', 'en'])
        
        results = self.ocr_reader.readtext(str(path))
        text = "\n".join([r[1] for r in results])
        return self._chunk_text(text, page=1)
    
    def _chunk_text(self, text: str, page: int) -> List[Dict]:
        """í…ìŠ¤íŠ¸ë¥¼ ì²­í¬ë¡œ ë¶„í• """
        chunks = []
        words = text.split()
        current_chunk = []
        current_length = 0
        
        for word in words:
            if current_length + len(word) + 1 > self.chunk_size and current_chunk:
                chunk_text = " ".join(current_chunk)
                chunks.append({
                    "text": chunk_text,
                    "page": page,
                    "type": "text",
                    "metadata": {}
                })
                # ì˜¤ë²„ë©
                overlap_words = current_chunk[-20:]  # ë§ˆì§€ë§‰ 20ë‹¨ì–´
                current_chunk = overlap_words
                current_length = sum(len(w) for w in current_chunk)
            
            current_chunk.append(word)
            current_length += len(word) + 1
        
        if current_chunk:
            chunk_text = " ".join(current_chunk)
            chunks.append({
                "text": chunk_text,
                "page": page,
                "type": "text",
                "metadata": {}
            })
        
        return chunks
    
    def _table_to_markdown(self, table: List[List]) -> str:
        """í‘œ ë°ì´í„°ë¥¼ Markdown í˜•ì‹ìœ¼ë¡œ ë³€í™˜"""
        if not table or not table[0]:
            return ""
        
        lines = []
        
        # í—¤ë”
        header = [str(cell) if cell else "" for cell in table[0]]
        lines.append("| " + " | ".join(header) + " |")
        lines.append("| " + " | ".join(["---"] * len(header)) + " |")
        
        # ë°ì´í„° í–‰
        for row in table[1:]:
            cells = [str(cell) if cell else "" for cell in row]
            # ì—´ ê°œìˆ˜ ë§ì¶”ê¸°
            while len(cells) < len(header):
                cells.append("")
            lines.append("| " + " | ".join(cells[:len(header)]) + " |")
        
        return "\n".join(lines)
```

---

### 4.10 core/rag_system.py ì‘ì„± (í•µì‹¬)

> âš ï¸ ì´ íŒŒì¼ë„ ë§¤ìš° ê¸¸ê¸° ë•Œë¬¸ì— í•µì‹¬ êµ¬ì¡°ë§Œ ì œì‹œí•©ë‹ˆë‹¤.

**íŒŒì¼: `backend/core/rag_system.py`**
```python
"""RAG ì‹œìŠ¤í…œ í•µì‹¬ ëª¨ë“ˆ"""
import hashlib
from pathlib import Path
from typing import Dict, List, Any
import chromadb
from sentence_transformers import SentenceTransformer
import ollama
from rank_bm25 import BM25Okapi

from config import (
    CHROMA_PERSIST_DIR, CHROMA_COLLECTION_NAME,
    EMBEDDING_MODEL, EMBEDDING_DEVICE,
    OLLAMA_BASE_URL, OLLAMA_MODEL,
    TOP_K_RESULTS, RERANK_TOP_K, RERANK_ENABLED,
    VECTOR_WEIGHT, BM25_WEIGHT,
    MIN_CONTEXT_COUNT, MAX_CONTEXT_COUNT
)
from .document_processor import DocumentProcessor
from .filename_parser import parse_filename
from .logger import logger


class RAGSystem:
    """RAG ì‹œìŠ¤í…œ ë©”ì¸ í´ë˜ìŠ¤"""
    
    def __init__(self):
        logger.info("RAG", "=== RAG System ì´ˆê¸°í™” ===")
        
        # ChromaDB ì´ˆê¸°í™”
        logger.info("RAG", "ChromaDB ì—°ê²°...")
        self.chroma_client = chromadb.PersistentClient(path=CHROMA_PERSIST_DIR)
        self.collection = self.chroma_client.get_or_create_collection(
            name=CHROMA_COLLECTION_NAME,
            metadata={"hnsw:space": "cosine"}
        )
        
        # ì„ë² ë”© ëª¨ë¸ ë¡œë”©
        logger.info("RAG", f"ì„ë² ë”© ëª¨ë¸ ë¡œë”©: {EMBEDDING_MODEL}")
        self.embedding_model = SentenceTransformer(
            EMBEDDING_MODEL,
            device=EMBEDDING_DEVICE
        )
        
        # Ollama ì„¤ì •
        self.ollama_base_url = OLLAMA_BASE_URL
        self.ollama_model = OLLAMA_MODEL
        logger.info("RAG", f"Ollama ëª¨ë¸: {OLLAMA_MODEL}")
        
        # ë¬¸ì„œ ì²˜ë¦¬ê¸°
        self.document_processor = DocumentProcessor()
        
        # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸
        self.system_prompt = """ë„ˆëŠ” ê¸°ì—… ë‚´ë¶€ ë¬¸ì„œë¥¼ ë¶„ì„í•˜ëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ì´ë‹¤.
ì œê³µëœ ì»¨í…ìŠ¤íŠ¸ë§Œì„ ê¸°ë°˜ìœ¼ë¡œ ë‹µë³€í•˜ê³ , ì •ë³´ê°€ ì—†ìœ¼ë©´ "í•´ë‹¹ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤"ë¼ê³  ë‹µí•´ë¼.
ë‹µë³€ ëì— ë°˜ë“œì‹œ [ì¶œì²˜: íŒŒì¼ëª…, í˜ì´ì§€ X]ë¥¼ í‘œì‹œí•˜ë¼."""
        
        logger.success("RAG", "=== ì´ˆê¸°í™” ì™„ë£Œ ===")
    
    def index_document(self, file_path: str, filename: str = None) -> Dict:
        """ë¬¸ì„œë¥¼ ì¸ë±ì‹±"""
        path = Path(file_path)
        if filename is None:
            filename = path.name
        
        logger.info("INDEX", f"ë¬¸ì„œ ì¸ë±ì‹± ì‹œì‘: {filename}")
        
        # íŒŒì¼ ID ìƒì„±
        file_id = hashlib.md5(filename.encode()).hexdigest()
        
        # íŒŒì¼ëª…ì—ì„œ ë©”íƒ€ë°ì´í„° ì¶”ì¶œ
        parsed = parse_filename(filename)
        file_ext = path.suffix.lower()
        
        # ë¬¸ì„œ ì²˜ë¦¬
        chunks = self.document_processor.process(str(path), filename)
        logger.info("INDEX", f"ì²­í¬ ìˆ˜: {len(chunks)}")
        
        # ì²­í¬ ì €ì¥
        for i, chunk in enumerate(chunks):
            chunk_id = f"{file_id}_{i}"
            
            # ì„ë² ë”© ìƒì„±
            embedding = self.embedding_model.encode(chunk["text"]).tolist()
            
            # ë©”íƒ€ë°ì´í„° êµ¬ì„±
            metadata = {
                "file_id": file_id,
                "filename": filename,
                "page": chunk.get("page", 1),
                "type": chunk.get("type", "text"),
                "chunk_index": i,
                "file_extension": file_ext,
                "has_table": chunk.get("metadata", {}).get("has_table", False),
            }
            
            if parsed["parsed"]:
                metadata.update({
                    "date": parsed["date"],
                    "doc_type": parsed["doc_type"],
                    "doc_title": parsed["doc_title"],
                })
            
            # ChromaDBì— ì €ì¥
            self.collection.add(
                ids=[chunk_id],
                embeddings=[embedding],
                documents=[chunk["text"]],
                metadatas=[metadata]
            )
        
        logger.success("INDEX", f"ì¸ë±ì‹± ì™„ë£Œ: {len(chunks)} ì²­í¬")
        
        return {
            "file_id": file_id,
            "chunks_count": len(chunks)
        }
    
    def query(self, query_text: str) -> Dict:
        """ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ ìƒì„±"""
        logger.info("QUERY", f"ì§ˆë¬¸: {query_text[:50]}...")
        
        # 1. ì¿¼ë¦¬ ì„ë² ë”©
        query_embedding = self.embedding_model.encode(query_text).tolist()
        
        # 2. ë²¡í„° ê²€ìƒ‰
        results = self.collection.query(
            query_embeddings=[query_embedding],
            n_results=TOP_K_RESULTS,
            include=["documents", "metadatas", "distances"]
        )
        
        if not results["documents"][0]:
            return {
                "answer": "ê´€ë ¨ ë¬¸ì„œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.",
                "sources": [],
                "has_answer": False
            }
        
        # 3. ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±
        context_parts = []
        sources = []
        
        for i, (doc, meta) in enumerate(zip(
            results["documents"][0][:RERANK_TOP_K],
            results["metadatas"][0][:RERANK_TOP_K]
        )):
            filename = meta.get("filename", "ì•Œ ìˆ˜ ì—†ìŒ")
            page = meta.get("page", "?")
            context_parts.append(f"[ë¬¸ì„œ {i+1}: {filename}, í˜ì´ì§€ {page}]\n{doc}")
            sources.append({
                "filename": filename,
                "page": page,
                "doc_type": meta.get("doc_type"),
            })
        
        context = "\n\n".join(context_parts)
        
        # 4. LLMìœ¼ë¡œ ë‹µë³€ ìƒì„±
        user_prompt = f"""ì»¨í…ìŠ¤íŠ¸:
{context}

ì§ˆë¬¸: {query_text}

ìœ„ ì»¨í…ìŠ¤íŠ¸ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì§ˆë¬¸ì— ë‹µë³€í•´ì£¼ì„¸ìš”."""
        
        client = ollama.Client(host=self.ollama_base_url)
        response = client.chat(
            model=self.ollama_model,
            messages=[
                {"role": "system", "content": self.system_prompt},
                {"role": "user", "content": user_prompt}
            ],
            options={
                "temperature": 0.0,
                "top_p": 0.7,
                "num_predict": 1500,
            }
        )
        
        answer = response["message"]["content"]
        logger.success("QUERY", "ë‹µë³€ ìƒì„± ì™„ë£Œ")
        
        return {
            "answer": answer,
            "sources": sources[:5],  # ìƒìœ„ 5ê°œ ì¶œì²˜ë§Œ
            "has_answer": True
        }
    
    def delete_document(self, file_id: str) -> int:
        """ë¬¸ì„œ ì‚­ì œ"""
        results = self.collection.get(
            where={"file_id": file_id},
            include=["metadatas"]
        )
        
        if results["ids"]:
            self.collection.delete(ids=results["ids"])
            logger.success("DELETE", f"{len(results['ids'])} ì²­í¬ ì‚­ì œ")
            return len(results["ids"])
        
        return 0
    
    def delete_document_by_filename(self, filename: str) -> int:
        """íŒŒì¼ëª…ìœ¼ë¡œ ë¬¸ì„œ ì‚­ì œ"""
        results = self.collection.get(
            where={"filename": filename},
            include=["metadatas"]
        )
        
        if results["ids"]:
            self.collection.delete(ids=results["ids"])
            return len(results["ids"])
        
        return 0
    
    def check_duplicate_document(self, filename: str) -> Dict:
        """ì¤‘ë³µ ë¬¸ì„œ í™•ì¸"""
        file_id = hashlib.md5(filename.encode()).hexdigest()
        results = self.collection.get(
            where={"file_id": file_id},
            include=["metadatas"]
        )
        
        if results["ids"]:
            return {
                "is_duplicate": True,
                "message": f"'{filename}' íŒŒì¼ì´ ì´ë¯¸ ì¡´ì¬í•©ë‹ˆë‹¤.",
                "existing_file_id": file_id
            }
        
        return {"is_duplicate": False}
    
    def get_all_document_types(self) -> Dict[str, int]:
        """ëª¨ë“  ë¬¸ì„œ ìœ í˜•ê³¼ ê°œìˆ˜ ë°˜í™˜"""
        results = self.collection.get(include=["metadatas"])
        
        doc_types = {}
        seen_files = set()
        
        for meta in results["metadatas"]:
            filename = meta.get("filename")
            if filename and filename not in seen_files:
                seen_files.add(filename)
                doc_type = meta.get("doc_type")
                if doc_type:
                    doc_types[doc_type] = doc_types.get(doc_type, 0) + 1
        
        return doc_types
```

---

### 4.11 app.py ì‘ì„±

**íŒŒì¼: `backend/app.py`**
```python
from flask import Flask, request, jsonify, send_file
from flask_cors import CORS
import os
import sys
import subprocess
import time
import requests
from pathlib import Path
from werkzeug.utils import secure_filename
from config import *

# ì¶œë ¥ ë²„í¼ë§ ë¹„í™œì„±í™”
os.environ['PYTHONUNBUFFERED'] = '1'

def check_ollama_running():
    """Ollama ì„œë²„ê°€ ì‹¤í–‰ ì¤‘ì¸ì§€ í™•ì¸"""
    try:
        response = requests.get(f"{OLLAMA_BASE_URL}/api/tags", timeout=2)
        return response.status_code == 200
    except:
        return False

def start_ollama_server():
    """Ollama ì„œë²„ë¥¼ ë°±ê·¸ë¼ìš´ë“œë¡œ ì‹œì‘"""
    print("[OLLAMA] Checking Ollama server status...")
    
    if check_ollama_running():
        print("[OLLAMA] Ollama server is already running")
        return True
    
    print("[OLLAMA] Starting Ollama server...")
    
    try:
        if sys.platform == "win32":
            CREATE_NO_WINDOW = 0x08000000
            subprocess.Popen(
                ["ollama", "serve"],
                stdout=subprocess.DEVNULL,
                stderr=subprocess.DEVNULL,
                creationflags=CREATE_NO_WINDOW
            )
        else:
            subprocess.Popen(
                ["ollama", "serve"],
                stdout=subprocess.DEVNULL,
                stderr=subprocess.DEVNULL,
                start_new_session=True
            )
        
        # Ollamaê°€ ì¤€ë¹„ë  ë•Œê¹Œì§€ ëŒ€ê¸° (ìµœëŒ€ 30ì´ˆ)
        for i in range(30):
            time.sleep(1)
            if check_ollama_running():
                print(f"[OLLAMA] Server started (took {i+1}s)")
                return True
        
        print("[OLLAMA] WARNING: Server did not start within 30s")
        return False
        
    except FileNotFoundError:
        print("[OLLAMA] ERROR: 'ollama' command not found")
        return False

# Ollama ì„œë²„ ìë™ ì‹œì‘
start_ollama_server()

from core.rag_system import RAGSystem
from core.file_manager import FileManager

app = Flask(__name__)
CORS(app)

# ì‹œìŠ¤í…œ ì´ˆê¸°í™”
rag_system = RAGSystem()
file_manager = FileManager()

@app.route("/api/health", methods=["GET"])
def health():
    return jsonify({"status": "healthy"})

@app.route("/api/upload", methods=["POST"])
def upload_file():
    try:
        if "file" not in request.files:
            return jsonify({"error": "No file provided"}), 400
        
        file = request.files["file"]
        if file.filename == "":
            return jsonify({"error": "Empty filename"}), 400
        
        # íŒŒì¼ í™•ì¥ì ê²€ì¦
        file_ext = Path(file.filename).suffix.lower()
        if file_ext not in ALLOWED_EXTENSIONS:
            return jsonify({"error": f"Unsupported: {file_ext}"}), 400
        
        original_filename = file.filename
        
        # ì¤‘ë³µ í™•ì¸
        dup_check = rag_system.check_duplicate_document(original_filename)
        if dup_check["is_duplicate"]:
            return jsonify({"error": "Duplicate", "is_duplicate": True}), 409
        
        # íŒŒì¼ ì €ì¥
        safe_filename = secure_filename(file.filename)
        file_path = file_manager.save_file(file, safe_filename, original_filename)
        
        # ì¸ë±ì‹±
        result = rag_system.index_document(file_path, original_filename)
        
        return jsonify({
            "success": True,
            "filename": original_filename,
            "file_id": result["file_id"],
            "chunks_count": result["chunks_count"]
        })
        
    except Exception as e:
        return jsonify({"error": str(e)}), 500

@app.route("/api/files", methods=["GET"])
def list_files():
    try:
        files = file_manager.list_files()
        
        from core.filename_parser import parse_filename
        for f in files:
            parsed = parse_filename(f["filename"])
            f.update({
                "date": parsed.get("date"),
                "doc_type": parsed.get("doc_type"),
                "doc_title": parsed.get("doc_title")
            })
        
        return jsonify({"files": files})
    except Exception as e:
        return jsonify({"error": str(e)}), 500

@app.route("/api/files/<file_id>", methods=["DELETE"])
def delete_file(file_id):
    try:
        # íŒŒì¼ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
        file_info = None
        for f in file_manager.list_files():
            if f["id"] == file_id:
                file_info = f
                break
        
        # ë²¡í„° DBì—ì„œ ì‚­ì œ
        deleted = 0
        if file_info:
            deleted = rag_system.delete_document_by_filename(file_info["filename"])
        if deleted == 0:
            deleted = rag_system.delete_document(file_id)
        
        # íŒŒì¼ ì‚­ì œ
        file_manager.delete_file(file_id)
        
        return jsonify({"success": True, "deleted_chunks": deleted})
    except Exception as e:
        return jsonify({"error": str(e)}), 500

@app.route("/api/query", methods=["POST"])
def query():
    try:
        data = request.json
        query_text = data.get("query")
        
        if not query_text:
            return jsonify({"error": "Query required"}), 400
        
        result = rag_system.query(query_text)
        
        return jsonify({
            "answer": result["answer"],
            "sources": result["sources"],
            "has_answer": result["has_answer"]
        })
        
    except Exception as e:
        return jsonify({
            "error": str(e),
            "answer": f"ì˜¤ë¥˜: {str(e)}",
            "sources": [],
            "has_answer": False
        }), 500

if __name__ == "__main__":
    print("Starting Private RAG API...")
    print(f"Ollama: {OLLAMA_BASE_URL}")
    app.run(host="0.0.0.0", port=5000, debug=False)
```

---

## 5. í”„ë¡ íŠ¸ì—”ë“œ êµ¬í˜„

### 5.1 package.json ì‘ì„±

```powershell
cd ..\frontend
```

**íŒŒì¼: `frontend/package.json`**
```json
{
  "name": "private-rag-frontend",
  "private": true,
  "version": "1.0.0",
  "type": "module",
  "scripts": {
    "dev": "vite",
    "build": "vite build",
    "preview": "vite preview"
  },
  "dependencies": {
    "react": "^18.2.0",
    "react-dom": "^18.2.0",
    "axios": "^1.6.2"
  },
  "devDependencies": {
    "@types/react": "^18.2.43",
    "@types/react-dom": "^18.2.17",
    "@vitejs/plugin-react": "^4.2.1",
    "vite": "^5.0.8"
  }
}
```

### 5.2 vite.config.js ì‘ì„±

**íŒŒì¼: `frontend/vite.config.js`**
```javascript
import { defineConfig } from 'vite'
import react from '@vitejs/plugin-react'

export default defineConfig({
  plugins: [react()],
  server: {
    port: 5173,
    proxy: {
      '/api': {
        target: 'http://localhost:5000',
        changeOrigin: true
      }
    }
  }
})
```

### 5.3 index.html ì‘ì„±

**íŒŒì¼: `frontend/index.html`**
```html
<!DOCTYPE html>
<html lang="ko">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Private RAG System</title>
  </head>
  <body>
    <div id="root"></div>
    <script type="module" src="/src/main.jsx"></script>
  </body>
</html>
```

### 5.4 src/main.jsx ì‘ì„±

**íŒŒì¼: `frontend/src/main.jsx`**
```jsx
import React from 'react'
import ReactDOM from 'react-dom/client'
import App from './App.jsx'
import './index.css'

ReactDOM.createRoot(document.getElementById('root')).render(
  <React.StrictMode>
    <App />
  </React.StrictMode>,
)
```

### 5.5 src/App.jsx ì‘ì„±

**íŒŒì¼: `frontend/src/App.jsx`**
```jsx
import { useState, useEffect } from 'react'
import FileManager from './components/FileManager'
import ChatInterface from './components/ChatInterface'
import './App.css'

function App() {
  const [activeTab, setActiveTab] = useState('chat')
  const [isConnected, setIsConnected] = useState(false)

  useEffect(() => {
    // ë°±ì—”ë“œ ì—°ê²° í™•ì¸
    fetch('/api/health')
      .then(res => res.json())
      .then(() => setIsConnected(true))
      .catch(() => setIsConnected(false))
  }, [])

  return (
    <div className="app">
      <header className="header">
        <h1>ğŸ”’ Private RAG System</h1>
        <div className={`status ${isConnected ? 'connected' : 'disconnected'}`}>
          {isConnected ? 'ë°±ì—”ë“œ ì—°ê²°ë¨' : 'ì—°ê²° ì¤‘...'}
        </div>
      </header>
      
      <nav className="tabs">
        <button 
          className={activeTab === 'chat' ? 'active' : ''} 
          onClick={() => setActiveTab('chat')}
        >
          ğŸ’¬ ì±„íŒ…
        </button>
        <button 
          className={activeTab === 'files' ? 'active' : ''} 
          onClick={() => setActiveTab('files')}
        >
          ğŸ“ íŒŒì¼ ê´€ë¦¬
        </button>
      </nav>
      
      <main className="main-content">
        {activeTab === 'chat' && <ChatInterface />}
        {activeTab === 'files' && <FileManager />}
      </main>
    </div>
  )
}

export default App
```

### 5.6 src/components/ChatInterface.jsx ì‘ì„±

**íŒŒì¼: `frontend/src/components/ChatInterface.jsx`**
```jsx
import { useState } from 'react'
import './ChatInterface.css'

function ChatInterface() {
  const [messages, setMessages] = useState([])
  const [input, setInput] = useState('')
  const [loading, setLoading] = useState(false)

  const handleSubmit = async (e) => {
    e.preventDefault()
    if (!input.trim() || loading) return

    const userMessage = input.trim()
    setInput('')
    setMessages(prev => [...prev, { role: 'user', content: userMessage }])
    setLoading(true)

    try {
      const response = await fetch('/api/query', {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({ query: userMessage })
      })
      
      const data = await response.json()
      
      setMessages(prev => [...prev, { 
        role: 'assistant', 
        content: data.answer,
        sources: data.sources 
      }])
    } catch (error) {
      setMessages(prev => [...prev, { 
        role: 'assistant', 
        content: 'ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: ' + error.message 
      }])
    } finally {
      setLoading(false)
    }
  }

  return (
    <div className="chat-interface">
      <div className="messages">
        {messages.length === 0 && (
          <div className="empty-state">
            ë¬¸ì„œì— ëŒ€í•´ ì§ˆë¬¸í•´ë³´ì„¸ìš”!
          </div>
        )}
        
        {messages.map((msg, i) => (
          <div key={i} className={`message ${msg.role}`}>
            <div className="content">{msg.content}</div>
            {msg.sources && msg.sources.length > 0 && (
              <div className="sources">
                ì¶œì²˜: {msg.sources.map(s => s.filename).join(', ')}
              </div>
            )}
          </div>
        ))}
        
        {loading && (
          <div className="message assistant">
            <div className="content">ìƒê°í•˜ëŠ” ì¤‘...</div>
          </div>
        )}
      </div>
      
      <form onSubmit={handleSubmit} className="input-form">
        <input
          type="text"
          value={input}
          onChange={(e) => setInput(e.target.value)}
          placeholder="ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”..."
          disabled={loading}
        />
        <button type="submit" disabled={loading}>ì „ì†¡</button>
      </form>
    </div>
  )
}

export default ChatInterface
```

### 5.7 src/components/FileManager.jsx ì‘ì„±

**íŒŒì¼: `frontend/src/components/FileManager.jsx`**
```jsx
import { useState, useEffect } from 'react'
import './FileManager.css'

function FileManager() {
  const [files, setFiles] = useState([])
  const [uploading, setUploading] = useState(false)
  const [message, setMessage] = useState('')

  const fetchFiles = async () => {
    try {
      const response = await fetch('/api/files')
      const data = await response.json()
      setFiles(data.files || [])
    } catch (error) {
      console.error('íŒŒì¼ ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨:', error)
    }
  }

  useEffect(() => {
    fetchFiles()
  }, [])

  const handleUpload = async (e) => {
    const file = e.target.files[0]
    if (!file) return

    setUploading(true)
    setMessage('ì—…ë¡œë“œ ì¤‘...')

    const formData = new FormData()
    formData.append('file', file)

    try {
      const response = await fetch('/api/upload', {
        method: 'POST',
        body: formData
      })
      
      const data = await response.json()
      
      if (response.ok) {
        setMessage(`âœ… ì—…ë¡œë“œ ì™„ë£Œ: ${data.chunks_count}ê°œ ì²­í¬ ìƒì„±`)
        fetchFiles()
      } else {
        setMessage(`âŒ ì˜¤ë¥˜: ${data.error}`)
      }
    } catch (error) {
      setMessage(`âŒ ì—…ë¡œë“œ ì‹¤íŒ¨: ${error.message}`)
    } finally {
      setUploading(false)
      e.target.value = ''
    }
  }

  const handleDelete = async (fileId, filename) => {
    if (!confirm(`"${filename}"ì„(ë¥¼) ì‚­ì œí•˜ì‹œê² ìŠµë‹ˆê¹Œ?`)) return

    try {
      const response = await fetch(`/api/files/${fileId}`, {
        method: 'DELETE'
      })
      
      if (response.ok) {
        setMessage(`âœ… "${filename}" ì‚­ì œ ì™„ë£Œ`)
        fetchFiles()
      } else {
        const data = await response.json()
        setMessage(`âŒ ì‚­ì œ ì‹¤íŒ¨: ${data.error}`)
      }
    } catch (error) {
      setMessage(`âŒ ì‚­ì œ ì‹¤íŒ¨: ${error.message}`)
    }
  }

  return (
    <div className="file-manager">
      <div className="upload-section">
        <label className="upload-button">
          ğŸ“¤ íŒŒì¼ ì—…ë¡œë“œ
          <input 
            type="file" 
            onChange={handleUpload}
            disabled={uploading}
            accept=".pdf,.docx,.xlsx,.xls,.txt"
          />
        </label>
        {message && <div className="message">{message}</div>}
      </div>
      
      <div className="file-list">
        <h3>ì—…ë¡œë“œëœ íŒŒì¼ ({files.length}ê°œ)</h3>
        
        {files.length === 0 ? (
          <p className="empty">ì—…ë¡œë“œëœ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.</p>
        ) : (
          <table>
            <thead>
              <tr>
                <th>íŒŒì¼ëª…</th>
                <th>ë¬¸ì„œ ìœ í˜•</th>
                <th>ë‚ ì§œ</th>
                <th>ì‘ì—…</th>
              </tr>
            </thead>
            <tbody>
              {files.map(file => (
                <tr key={file.id}>
                  <td>{file.filename}</td>
                  <td>{file.doc_type || '-'}</td>
                  <td>{file.date || '-'}</td>
                  <td>
                    <button 
                      onClick={() => handleDelete(file.id, file.filename)}
                      className="delete-btn"
                    >
                      ğŸ—‘ï¸
                    </button>
                  </td>
                </tr>
              ))}
            </tbody>
          </table>
        )}
      </div>
    </div>
  )
}

export default FileManager
```

### 5.8 CSS íŒŒì¼ ì‘ì„±

**íŒŒì¼: `frontend/src/index.css`**
```css
* {
  margin: 0;
  padding: 0;
  box-sizing: border-box;
}

body {
  font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;
  background: #f5f5f5;
  color: #333;
}
```

**íŒŒì¼: `frontend/src/App.css`**
```css
.app {
  min-height: 100vh;
  display: flex;
  flex-direction: column;
}

.header {
  background: #1a1a2e;
  color: white;
  padding: 1rem 2rem;
  display: flex;
  justify-content: space-between;
  align-items: center;
}

.header h1 {
  font-size: 1.5rem;
}

.status {
  padding: 0.5rem 1rem;
  border-radius: 20px;
  font-size: 0.875rem;
}

.status.connected {
  background: #2ecc71;
}

.status.disconnected {
  background: #e74c3c;
}

.tabs {
  background: #16213e;
  padding: 0 2rem;
  display: flex;
  gap: 0.5rem;
}

.tabs button {
  background: transparent;
  border: none;
  color: #aaa;
  padding: 1rem 1.5rem;
  cursor: pointer;
  font-size: 1rem;
  border-bottom: 3px solid transparent;
}

.tabs button.active {
  color: white;
  border-bottom-color: #3498db;
}

.main-content {
  flex: 1;
  padding: 2rem;
  max-width: 1200px;
  margin: 0 auto;
  width: 100%;
}
```

**íŒŒì¼: `frontend/src/components/ChatInterface.css`**
```css
.chat-interface {
  display: flex;
  flex-direction: column;
  height: calc(100vh - 200px);
  background: white;
  border-radius: 12px;
  overflow: hidden;
  box-shadow: 0 2px 10px rgba(0,0,0,0.1);
}

.messages {
  flex: 1;
  overflow-y: auto;
  padding: 1.5rem;
}

.empty-state {
  text-align: center;
  color: #999;
  padding: 3rem;
}

.message {
  margin-bottom: 1rem;
  max-width: 80%;
}

.message.user {
  margin-left: auto;
}

.message.user .content {
  background: #3498db;
  color: white;
  border-radius: 18px 18px 4px 18px;
  padding: 0.75rem 1rem;
}

.message.assistant .content {
  background: #f0f0f0;
  border-radius: 18px 18px 18px 4px;
  padding: 0.75rem 1rem;
}

.message .sources {
  font-size: 0.75rem;
  color: #666;
  margin-top: 0.5rem;
}

.input-form {
  display: flex;
  padding: 1rem;
  border-top: 1px solid #eee;
  gap: 0.5rem;
}

.input-form input {
  flex: 1;
  padding: 0.75rem 1rem;
  border: 1px solid #ddd;
  border-radius: 24px;
  font-size: 1rem;
}

.input-form button {
  padding: 0.75rem 1.5rem;
  background: #3498db;
  color: white;
  border: none;
  border-radius: 24px;
  cursor: pointer;
}
```

**íŒŒì¼: `frontend/src/components/FileManager.css`**
```css
.file-manager {
  background: white;
  border-radius: 12px;
  padding: 1.5rem;
  box-shadow: 0 2px 10px rgba(0,0,0,0.1);
}

.upload-section {
  margin-bottom: 2rem;
}

.upload-button {
  display: inline-block;
  padding: 0.75rem 1.5rem;
  background: #3498db;
  color: white;
  border-radius: 8px;
  cursor: pointer;
}

.upload-button input {
  display: none;
}

.upload-section .message {
  margin-top: 1rem;
  padding: 0.75rem;
  background: #f8f9fa;
  border-radius: 8px;
}

.file-list h3 {
  margin-bottom: 1rem;
}

.file-list table {
  width: 100%;
  border-collapse: collapse;
}

.file-list th, .file-list td {
  padding: 0.75rem;
  text-align: left;
  border-bottom: 1px solid #eee;
}

.file-list th {
  background: #f8f9fa;
  font-weight: 600;
}

.delete-btn {
  background: none;
  border: none;
  cursor: pointer;
  font-size: 1.2rem;
}

.empty {
  color: #999;
  text-align: center;
  padding: 2rem;
}
```

### 5.9 íŒ¨í‚¤ì§€ ì„¤ì¹˜

```powershell
npm install
```

---

## 6. AI ëª¨ë¸ ì„¤ì •

### 6.1 LLM ëª¨ë¸ ë‹¤ìš´ë¡œë“œ

```powershell
# llama3.1 8B ëª¨ë¸ ë‹¤ìš´ë¡œë“œ (ì•½ 4.7GB)
ollama pull llama3.1:8b-instruct-q4_K_M

# í™•ì¸
ollama list
```

### 6.2 ì„ë² ë”© ëª¨ë¸ ì‚¬ì „ ë‹¤ìš´ë¡œë“œ (ì„ íƒ)

```powershell
cd backend
.\venv311\Scripts\Activate.ps1

python -c "from sentence_transformers import SentenceTransformer; SentenceTransformer('BAAI/bge-m3')"
```

---

## 7. ì‹¤í–‰ ë° í…ŒìŠ¤íŠ¸

### 7.1 ë°±ì—”ë“œ ì‹¤í–‰

**í„°ë¯¸ë„ 1**:
```powershell
cd C:\Users\ì‚¬ìš©ìì´ë¦„\Documents\RAG_Private\backend
.\venv311\Scripts\Activate.ps1
python -u app.py
```

**ì •ìƒ ì¶œë ¥**:
```
[OLLAMA] Checking Ollama server status...
[OLLAMA] Ollama server is already running
=== RAG System ì´ˆê¸°í™” ===
ChromaDB ì—°ê²°...
ì„ë² ë”© ëª¨ë¸ ë¡œë”©: BAAI/bge-m3
=== ì´ˆê¸°í™” ì™„ë£Œ ===
Starting Private RAG API...
 * Running on http://0.0.0.0:5000
```

### 7.2 í”„ë¡ íŠ¸ì—”ë“œ ì‹¤í–‰

**í„°ë¯¸ë„ 2**:
```powershell
cd C:\Users\ì‚¬ìš©ìì´ë¦„\Documents\RAG_Private\frontend
npm run dev
```

**ì •ìƒ ì¶œë ¥**:
```
  VITE v5.x.x  ready in xxx ms

  âœ  Local:   http://localhost:5173/
```

### 7.3 í…ŒìŠ¤íŠ¸

1. ë¸Œë¼ìš°ì €ì—ì„œ http://localhost:5173 ì ‘ì†
2. "íŒŒì¼ ê´€ë¦¬" íƒ­ì—ì„œ PDF íŒŒì¼ ì—…ë¡œë“œ
3. "ì±„íŒ…" íƒ­ì—ì„œ ì§ˆë¬¸ ì…ë ¥
4. AI ë‹µë³€ í™•ì¸!

---

## ğŸ‰ ì™„ë£Œ!

ì²˜ìŒë¶€í„° Private RAG ì‹œìŠ¤í…œì„ ì„±ê³µì ìœ¼ë¡œ êµ¬ì¶•í–ˆìŠµë‹ˆë‹¤!

### ë‹¤ìŒ ë‹¨ê³„

- ê³ ê¸‰ ê¸°ëŠ¥ ì¶”ê°€: í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰, Re-Ranking
- í‘œ ì²˜ë¦¬ ê³ ë„í™”: OpenCV í‘œ ì„  ê°ì§€
- UI ê°œì„ : ë¬¸ì„œ ìœ í˜• í•„í„°, ê²€ìƒ‰ ê¸°ë¡

### ì°¸ê³  ë¬¸ì„œ

- [ê¸°ìˆ  ëª…ì„¸ì„œ](./TECHNICAL_SPEC.md)
- [íŒŒì´í”„ë¼ì¸ ìƒì„¸](./PIPELINE.md)

---

*Last Updated: 2026-01-29*

