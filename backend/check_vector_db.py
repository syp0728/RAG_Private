"""ë²¡í„° DB ë‚´ìš© í™•ì¸ ìŠ¤í¬ë¦½íŠ¸"""
import sys
import json
from pathlib import Path
from collections import defaultdict
sys.path.insert(0, str(Path(__file__).parent))

import chromadb
from chromadb.config import Settings
from config import CHROMA_PERSIST_DIR, CHROMA_COLLECTION_NAME

def print_section(title):
    """ì„¹ì…˜ ì œëª© ì¶œë ¥"""
    print("\n" + "=" * 80)
    print(f"  {title}")
    print("=" * 80)

def format_text(text, max_length=100):
    """í…ìŠ¤íŠ¸ë¥¼ ì§€ì •ëœ ê¸¸ì´ë¡œ ìë¥´ê¸°"""
    if len(text) <= max_length:
        return text
    return text[:max_length] + "..."

# ChromaDB ì—°ê²°
client = chromadb.PersistentClient(
    path=CHROMA_PERSIST_DIR,
    settings=Settings(anonymized_telemetry=False)
)

collection = client.get_collection(CHROMA_COLLECTION_NAME)

# ëª¨ë“  ë¬¸ì„œ ê°€ì ¸ì˜¤ê¸°
all_docs = collection.get()

print_section("ë²¡í„° DB ì „ì²´ í†µê³„")
print(f"ì´ ì²­í¬ ìˆ˜: {len(all_docs['ids'])}")
print(f"ì»¬ë ‰ì…˜ ì´ë¦„: {CHROMA_COLLECTION_NAME}")
print(f"ì €ì¥ ê²½ë¡œ: {CHROMA_PERSIST_DIR}")

# íŒŒì¼ëª…ë³„ë¡œ ê·¸ë£¹í™”
file_groups = defaultdict(lambda: {
    'file_id': None,
    'chunks': [],
    'metadata': {}
})

for i, metadata in enumerate(all_docs['metadatas']):
    filename = metadata.get('filename', 'Unknown')
    file_id = metadata.get('file_id', 'Unknown')
    
    if file_groups[filename]['file_id'] is None:
        file_groups[filename]['file_id'] = file_id
        file_groups[filename]['metadata'] = {
            'date': metadata.get('date'),
            'doc_type': metadata.get('doc_type'),
            'doc_title': metadata.get('doc_title')
        }
    
    chunk_info = {
        'chunk_id': all_docs['ids'][i],
        'page': metadata.get('page', 'N/A'),
        'type': metadata.get('type', 'text'),
        'chunk_index': metadata.get('chunk_index', i),
        'text_preview': format_text(all_docs['documents'][i], 100)
    }
    file_groups[filename]['chunks'].append(chunk_info)

# í˜ì´ì§€ ìˆœì„œëŒ€ë¡œ ì •ë ¬
for filename in file_groups:
    file_groups[filename]['chunks'].sort(key=lambda x: x['page'] if isinstance(x['page'], (int, float)) else 0)

print_section("íŒŒì¼ë³„ ìƒì„¸ ì •ë³´")
for filename, info in sorted(file_groups.items()):
    print(f"\nğŸ“„ íŒŒì¼ëª…: {filename}")
    print(f"   File ID: {info['file_id']}")
    print(f"   ì²­í¬ ìˆ˜: {len(info['chunks'])}")
    
    meta = info['metadata']
    if meta['date'] or meta['doc_type'] or meta['doc_title']:
        print(f"   ë©”íƒ€ë°ì´í„°:")
        if meta['date']:
            print(f"     - ë‚ ì§œ: {meta['date']}")
        if meta['doc_type']:
            print(f"     - ë¬¸ì„œ ìœ í˜•: {meta['doc_type']}")
        if meta['doc_title']:
            print(f"     - ë¬¸ì„œ ì œëª©: {meta['doc_title']}")
    
    # í˜ì´ì§€ë³„ ì²­í¬ ìˆ˜
    page_counts = defaultdict(int)
    for chunk in info['chunks']:
        page = chunk['page']
        page_counts[page] += 1
    
    print(f"   í˜ì´ì§€ë³„ ì²­í¬ ë¶„í¬:")
    for page in sorted(page_counts.keys()):
        if isinstance(page, (int, float)):
            print(f"     - í˜ì´ì§€ {int(page)}: {page_counts[page]}ê°œ ì²­í¬")

print_section("ë¬¸ì„œ ìœ í˜•ë³„ í†µê³„")
doc_type_counts = defaultdict(lambda: {'files': set(), 'chunks': 0})

for filename, info in file_groups.items():
    doc_type = info['metadata'].get('doc_type')
    if doc_type:
        doc_type_counts[doc_type]['files'].add(filename)
        doc_type_counts[doc_type]['chunks'] += len(info['chunks'])

for doc_type, counts in sorted(doc_type_counts.items()):
    print(f"  {doc_type}:")
    print(f"    - íŒŒì¼ ìˆ˜: {len(counts['files'])}")
    print(f"    - ì²­í¬ ìˆ˜: {counts['chunks']}")

# íŠ¹ì • íŒŒì¼ì˜ ìƒì„¸ ë‚´ìš© ë³´ê¸° ì˜µì…˜
print_section("íŠ¹ì • íŒŒì¼ì˜ ì²­í¬ ë‚´ìš© ë³´ê¸°")
print("íŠ¹ì • íŒŒì¼ì˜ ìƒì„¸ ë‚´ìš©ì„ ë³´ë ¤ë©´ íŒŒì¼ëª…ì„ ì…ë ¥í•˜ì„¸ìš” (Enterë¡œ ê±´ë„ˆë›°ê¸°):")
filename_input = input("íŒŒì¼ëª…: ").strip()

if filename_input and filename_input in file_groups:
    info = file_groups[filename_input]
    print(f"\nğŸ“„ {filename_input} - ìƒì„¸ ì²­í¬ ë‚´ìš©")
    print(f"ì´ {len(info['chunks'])}ê°œ ì²­í¬\n")
    
    for i, chunk in enumerate(info['chunks'], 1):
        print(f"[ì²­í¬ {i}]")
        print(f"  ID: {chunk['chunk_id']}")
        print(f"  í˜ì´ì§€: {chunk['page']}")
        print(f"  íƒ€ì…: {chunk['type']}")
        print(f"  ì¸ë±ìŠ¤: {chunk['chunk_index']}")
        print(f"  ë‚´ìš© ë¯¸ë¦¬ë³´ê¸°: {chunk['text_preview']}")
        print()

# ìƒ˜í”Œ ë©”íƒ€ë°ì´í„° í™•ì¸
print_section("ìƒ˜í”Œ ë©”íƒ€ë°ì´í„° êµ¬ì¡°")
if all_docs['metadatas']:
    sample_metadata = all_docs['metadatas'][0]
    print("ì²« ë²ˆì§¸ ì²­í¬ì˜ ë©”íƒ€ë°ì´í„°:")
    print(json.dumps(sample_metadata, indent=2, ensure_ascii=False))

print("\n" + "=" * 80)
print("í™•ì¸ ì™„ë£Œ!")
print("=" * 80)

